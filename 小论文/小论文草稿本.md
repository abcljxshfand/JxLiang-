# 小论文草稿本

基于中间模态和混合注意力的跨模态行人重识别

# 摘要





# 引言

**思路：**

介绍行人重识别-引出跨模态行人重识别-介绍跨模态行人重识别现状-目前存在的问题-我提出的解决方案

![image-20230716091148863](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20230716091148863.png)

**正文：**

行人重识别（Person Re-Identification, ReID）是智能监控系统的关键技术之一，是指利用计算机视觉技术在指定视频或图片序列中对特定行人进行识别的技术，旨在解决不同摄像头之间的行人检索问题。近年来，ReID获得了相当大的关注，取得了不错的进展，

然而，可见光摄像头在弱光或者无光（例如夜晚）的环境下，并不能捕获到有效的行人信息，与可见光相机相比，红外（IR）相机可以在黑暗环境中从场景中捕获足够的信息。但是，由于可见光图像和红外图像之间存在巨大的差异，传统单模态的行人重识别模型难以处理这两种不同模态图像之间的行人重识别任务。

因此，为了更有效地进行两种模态图像间的行人重识别，研究人员提出了基于可见光——红外图像跨模态行人重识别问题（Visible-Infrared Person Re-Identification, VI ReID）。

有的解决跨模态行人重识别问题的方法可以分成以下两种方法：模态共享特征学习和模态互转。

模态共享特征学习主要通过特征对齐的方式，把红外图像和可见光图像的特征投影到一个统一的模态共享空间中，然后通过相关的损失函数进行度量学习，把不同模态、相同身份的行人特征距离拉近，同一模态不同身份的行人特征距离推远。2017年，Wu等人[18]在提出了深度零填充网络来学习可见光模态和红外模态的模态共享特征，该网络可以把两种模态投影到一个统一的共享空间进行模态共享特征的学习，并构建了第一个名为SYSU-MM01的大规模可见红外行人图像数据集。为了更好地约束模态内和模态间的变化，Ye等人在[20]中还提出了一种分层的跨模态匹配模型（HCML），该模型联合优化了模态特定特征和模态共享特征，把不同模态、相同身份的行人图像的距离拉近，相同模态、不同身份的行人图像距离推远。，Liu等人[22]首先从输入图像中提取模态共享特征，然后利用水平分割的方式来获得更具鉴别性的模态共享行人局部特征。

模态互转主要使用生成对抗网络来生成伪图像，例如通过可见光图像来生成红外伪图像，实现了从一种模态转变成另一种模态，把跨模态问题转变为单模态问题进行解决。Wang等人[28]提出了D2RL方法，该方法首先通过设计图像级子网络将红外图像转换为可见图像，将可见图像转换为红外图像，从而减少了模态差异。然后，提出了一个特征级子网络，通过引入一些特征级约束来减少剩余的外观差异。

一些工作从真的可见光图像中生成假红外图像进行补偿。例如，Wang等人[28]提出了第一个基于单模态信息补偿的工作，即对齐生成对抗网络（AlignGAN），该网络采用了两种对齐策略，包括像素级对齐和特征级对齐，用于VI ReID。具体而言，AlignGAN首先通过从真实可见图像生成假红外图像来实现像素级对准，然后通过特征对准模块匹配生成的假红外图像和真实红外图像。不同的是，一些工作采用了从真实红外图像生成假可见图像的方式进行补偿。例如，Dai等人[29]设计了一个名为CE2L的新模型，该模型首先通过图像模态转换模块将红外图像转换为可见图像，然后通过使用特征提取模块和VI ReID的特征学习模块学习其辨别特征。

与上面基于单模态信息补充工作不同的是，一些工作研究基于跨模态信息补偿的模型，旨在通过同时生成VI ReID的所有缺失模态特定信息。例如，Wang等人[30]提出了一种双水平差异减少学习（D2RL）策略。该策略首先通过设计图像级子网络将红外图像转换为可见图像，将可见图像转换为红外图像，从而减少了模态差异。然后，提出了一个特征级子网络，通过引入一些特征级约束来减少剩余的外观差异。

（介绍现有方法）

<font color='red'>控制篇幅，与下面你所提出的方法要有所对应</font>

（现有方法仍存在xxx问题）

现有方法主要通过生成对抗网络进行模态互转或直接提取原始图像的模态共享特征来缓解模态差异。但是，模态互转需要复杂的生成网络和判别网络，并且生成的伪图像与真实图像之间仍然存在差距，容易引入噪声。同时，由于可见光图像和红外图像之间的模态差异是高度非线性的，直接提取模态共享特征十分困难，而且不能充分挖掘细微的、更具鉴别性的特征信息。

因此，本文设计一种基于中间模态和混合注意力的跨模态行人重识别方法，能有效地缓解模态差异，同时挖掘细微的、更具鉴别性的特征信息。<font color='red'>（这里可以改一下，突出本文的贡献）</font>



主要

**草稿：**

行人重识别是图像检索的一个子问题，主要是实现从一个摄像机捕获行人图片到其他设备下中搜索具有相同ID图片的问题。早期的传统方法偏重于设计更适合的手工特征，同时在度量阶段，构建学习更有效的相似度度量。近些年来，基于深度学习方法的行人重识别方法在性能上远超于传统基于人工设计特征的方法，在现有的公开数据集上平均精度均值已经达到了九十多，但这些数据集均为可见光图像，模态单一，使用夜间拍摄到的红外图像进行检索时效果较差。为了实现全天候监控，基于可见光——红外图像跨模态行人重识别被提出，使不同模态的行人图像能够相互匹配，充分利用多种摄像头拍摄到的监控数据。

解决跨模态行人重识别的关键在于学习两种模态的共享特征, 减小不同模态之间的差异。起初有基于表征学习和基于度量学习这两种方法，基于表征学习方法是设计合理的网络架构，提取两种模态图像共享的具有鲁棒性和鉴别性的特征，缩小模态间存在的差异性。基于度量学习方法旨在设计合理的度量方法或损失函数，学习一个映射空间，使得不同模态的类内距离小于类间距离。2017年，Wu等人[1]首次提出基于可见光——红外线图像的跨模态行人重识别问题，并设计一种深度补零方法来训练单流网络，让网络根据输入的图像自动选择特定节点进行跨模态匹配。为了减少两种模态之间的差距，Ye等人[3]提出一种双流CNN网络(TONE)来学习两种异质模态的多模态共享特征表示。考虑到使用全局特征会忽略细节信息，Zhu等人[6]设计了双流局部特征网络(TSLFN)来学习跨模态行人重识别的局部特征表示,并联合异质中心损失和身份损失来训练网络，缩小每个类内两个模态特征分布之间的距离。Park等人[16]考虑到局部特征会受行人错位、遮挡等因素影响，提出特征对齐来促使模型提取鲁棒性特征。Yin等人[17]认为单使用局部特征获取的信息量少，引入了局部特征分块加权求和再和全局特征相加计算损失。随着生成对抗网络兴起, 出现了基于模态互转的学习方法，即将两种模态的图像数据转换成同一模态数据，减少两种模态的差异。Wang等人[7]提出一种双级差异减少方法(D2RL)，利用GAN将RGB(IR)图像生成其对应的IR(RGB)图像, 形成统一的多光谱图像，减少模态间差异。Li等人[8]提出生成一个中间模态，将可见光图像和红外图像之间的巨大差异缩小为两种模态和中间模态之间的较小差异。

现有方法大多采用深层网络参数共享的双流网络来提取两种模态的共享特征，但这不利于提取同模态下不同类之间的辨别性特征。使用局部特征虽然会使模型注意到一些细节信息，但会造成空间信息的缺失。**为此，本文设计了参数独立的双流网络来分别提取可见光图像和红外图像特征，融合改进后的自注意力机制增强模型提取特征的信息容量。采用灰度化的可见光图像作为辅助模态，减缓可见光图像和红外图像在色彩上的差异。使用身份损失和异质中心损失来训练模型，提高类内不同模态的特征相似度。**

# 相关方法

**思路：**

某一个点可以仿写，别全抄别人的框架、模型、思路





**正文：**

## 2.1网络总体架构

该方法的网络结构如下图1所示。首先，将原始的可见光图像与红外图像输入中间模态生成器，以生成中间模态图像。然后，生成的中间模态图像分别和原始的可见光图像与红外图像一同输入至主干网络中提取模态共享特征。主干网络基于ResNet50进行改进，前面两层网络层的参数是独立的，用于提取模态特定特征，后面的网络层参数共享，用于提取模态共享特征。在第三个网络层后面嵌入混合注意力引导学习模块，有效地缓解模态间的差异，同时充分挖掘具有鉴别性的模态共享特征。将从主干网络提取的特征图水平划分为若干个部分，每个部分都被输入到分类器中以学习具有鉴别性的模态共享特征。最后，联合使用分布一致性损失函数、三元组损失函数、身份损失函数来对模型进行端到端训练。

![image-20230716095813168](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20230716095813168.png)

（模型所用的辅助模态图重新弄一下）



## 2.2中间模态生成器

**正文：**

辅助模态生成器采用编码器-解码器架构，具体结构如下图所示，它由两个独立的解码器和一个参数共享的解码器构成。首先对图像进行预处理，把输入图片的尺寸大小统一调整为3x384x192，由于红外图像是单通道的，可见光图像是三通道的，因此我们把红外图像的通道数设置为3，和可见光图像的通道数保持一致。然后，把两种模态的图像输入至对应的模态信息编码器中进行编码，在编码过程中，首先会通过一个卷积核为3x1x1的卷积层，将三通道图像转换为单通道图像，然后通过卷积核为1x1x1的卷积层，减少计算量，最后通过批归一化层进行数据归一化。然后将归一化后的数据输入至对应的解码器进行解码，将编码后的单通道图像通过卷积核为1x3x1的卷积层转换为三通道图像，以生成对应的辅助模态图像。(用group norm替换成bn，原因讲一下。)



辅助模态生成器的结构如下图所示，由两个独立的非线性编码器和一个共享参数的解码器组成。两个独立的编码器对两种模态的图像进行编码。然后，通过两个参数共享的模态解码器将它们投影到到统一的中间模态图像空间中，以生成的图像具有统一的中间模态。最后中间模态图像、可见光模态图像和红外模态图像一起输入至主干网络中，以辅助VI-ReID任务，减缓模态间的差异。考虑到可见光图像和红外图像之间的非线性关系，将它们投影到统一的中间模态图像空间中，所提出的辅助模态生成器可以促进主干网络的优化过程。同时，主干网络的优化可以有效促进辅助模态生成器的学习，并进一步提高生成的辅助模态图像质量。（<font color='red'>话术还是要改一下，和英文有点相似了</font>）

![image-20230714102610110](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20230714102610110.png)





**草稿：**

众所周知，可见光图像是三通道的，红外图像是单通道的，因此三通道可见光图像与单通道红外图像的匹配方法是本节研究的重点。为了减少通道带来的影响，本文使用两个独立的编码器分别对两种模式的图像进行编码，然后通过共享解码器生成中间模式图像，其结构如图所示

从上图可以看出，中间模式生成器由编码器和解码器组成。中间模态生成器将具有相同标签的两种模态的图像对作为输入。输入图像尺寸统一调整为3×384×192，其中单通道红外图像复制到三个通道，以确保与三通道可见光图像对齐。然后，两种模态的图像都输入到编码器进行编码，首先通过Covn2d(3,1,1)将三通道图像转换为单通道图像，然后通过Covn2d(1,1,1)将减少计算量，最后通过BN层进行数据归一化。然后将归一化后的数据输入到解码器进行解码，将编码后的单通道图像通过Covn2d(1,3,1)转换为三通道图像，生成与可见图像具有相同标签的中间模态图像红外图像，其中可见光图像、红外图像和中模态图像如图3所示



## 2.3 模态共享特征提取网络（混合注意力引导学习模块）



本文设计了一个混合注意力引导学习模块，该模块可以减缓模态间的差异，同时充分挖掘不同行人图像间的细微信息。混合注意力引导学习模块结构如下图所示，该模块使用了实例归一化来减缓模态间的差异，（<font color='red'>分步</font>）同时使用卷积注意力模块（Convolutional Block Attention Module，CBAM）引导实例归一化，并充分挖掘特征图中的细微信息。模块具体的计算公式如下所示：



xxxxx（有点复杂，介绍实例归一化，介绍cbam，<font color='red'>分步介绍</font>？）

其中，xx表示xx，xx表示xx

该模块主要使用了实例归一化和混合注意力，实例归一化常用于图像迁移任务，可以有效地减缓模态差异。它的定义如下所示：



混合注意力引导学习模块结构如下图所示，为了减缓模态差异并充分挖掘身份信息，我们在卷积块提取的特征图上使用混合注意力来引导实例归一化。其中，实例归一化主要应用于图像迁移任务，它可以缓解模态间的差异。但是，直接使用实例归一化可能会丢失相关的身份信息，对VI-Reid任务造成影响。为了解决上述问题，使用卷积注意力模块（Convolutional Block Attention Module，CBAM）来引导实例归一化，同时帮助模型关注更具备鉴别性的特征信息。<font color='red'>（公式要写一下）</font>

![image-20230707161744561](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20230707161744561.png)

**草稿：**

对于输入图像 x，我们将卷积块提取的特征图 Z ∈ R h×w×c 表示为 MAM 的输入，其中 h、w、c 表示特征图的高度、宽度和尺寸。为了减轻模态差异，我们应用实例归一化（IN），它可以减少实例之间的差异[17]。然而，直接应用IN可能会损坏识别信息，从而对Re-ID任务产生不利影响。

为了克服这些缺点，我们应用通道注意力引导的 IN 来减轻模态差异，同时保留身份信息：



## 2.4损失函数

（和专利那里的差不多。）











# 实验





# 总结
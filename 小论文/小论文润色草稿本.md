# 小论文润色草稿本

# 摘要

摘要：本文针对跨模态行人重识别面临的挑战，即模态间的差异问题，提出了一种新的解决方案。该方案基于辅助模态生成器和混合注意力的双流参数共享网络，旨在减缓模态差异并挖掘更具鉴别性的特征信息。辅助模态生成器将可见光图像和红外图像转换为辅助模态图像，从而缓解模态间差异。混合注意力引导学习模块通过混合注意力和实例归一化引导模型关注更具鉴别性的特征。局部特征学习进一步提高性能。实验结果表明，在SYSU-MM01数据集的全局搜索模式下，Rank-1和mAP分别达到了67.08%和63.93%，证明了该方法的有效性。

# 引言

行人重识别（Person Re-Identification, ReID）是智能监控系统中的关键技术之一，用于在给定的视频或图像序列中对特定行人进行识别。其目标是解决不同摄像头之间的行人检索问题。近年来，ReID已经受到广泛关注并取得了不错的进展[1-3]。然而，可见光摄像头在弱光或无光的环境（例如夜晚）下，往往无法捕获到有效的行人信息。相比之下，红外相机可以在黑暗环境中从场景中获取足够的信息。但是，由于可见光图像和红外图像之间存在巨大的差异，传统的单模态行人重识别模型难以处理这两种不同模态图像之间的行人重识别任务。因此，为了更有效地进行两种模态图像之间的行人重识别，研究人员提出了基于可见光——红外图像的跨模态行人重识别问题（Visible-Infrared Person Re-Identification, VI ReID）。

 

目前，解决跨模态行人重识别问题的方法可以分为以下两种：模态共享特征学习和模态特定信息补偿。

 

模态共享特征学习主要通过特征对齐的方式，将红外图像和可见光图像投影到一个统一的模态共享空间中，然后利用相关的损失函数进行度量学习。这样做可以将不同模态但相同身份的行人特征距离拉近，同时将同一模态但不同身份的行人特征距离推远。例如，2017年，Wu等人[4]提出了一种能够在共享空间中学习模态共享特征的深度零填充网络，并创建了第一个大规模的可见光-红外行人图像数据集SYSU-MM01。Ye等人[5]则提出了双向双约束top-ranking损失，用于缓解模态内和模态间的差异，从而帮助模型提取具有鉴别性的行人特征信息。此外，Ye等人[6]还提出了一种基于双流网络的分层跨模态匹配模型，对模态特定特征和模态共享特征进行联合度量优化。而Liu等人[7]首先从输入图像中提取模态共享特征，然后通过水平分割的方式获得更具鉴别性的模态共享行人的局部特征。

 

模态特定信息补偿主要使用生成对抗网络来生成伪图像，从现有的模态特定信息中生成缺失的模态特定信息，以缓解不同模态间的差异。例如，Wang等人[8]提出了AlignGAN，该网络首先通过原始的可见光图像生成红外伪图像，实现像素级的特征对齐，然后将原始的红外图像和生成的红外伪图像进行匹配。另外，Wang等人[9]提出了一种基于双流网络的双层差异减少学习策略（D2RL），该策略主要通过可见光图像和红外图像之间的相互转化来减缓模态间的差异。还有Li等人[10]设计了一个轻量级网络，该网络能够将可见光图像生成一种新的辅助模态图像，从而减缓可见光模态和红外模态之间的模态差异。

 

通过分析研究现有方法，发现模态特定信息补偿需要复杂的生成对抗网络，且生成的伪图像容易引入噪声，从而影响模型性能。同时，由于可见光图像和红外图像之间的模态差异巨大，直接提取模态共享特征十分困难，且无法充分挖掘细微的、更具鉴别性的特征信息。

 

为了解决上述问题，本文设计了一个基于辅助模态生成器和混合注意力的双流参数共享网络，旨在减缓两种模态之间的差异，同时发掘更具鉴别性和鲁棒性的特征信息。所提出的网络基于Resnet50进行改进。首先，通过一个轻量级的辅助模态生成器，将可见光图像和红外图像投影到一个统一的辅助模态空间，以此生成相同模态的辅助模态图像。然后，将这些辅助模态图像与原始图像一起输入主干网络，以提取特征信息，从而有效减缓模态之间的差异。

 

在主干网络中，引入混合注意力引导学习模块，该模块利用混合注意力机制和实例归一化，有助于排除背景噪声的干扰，引导模型关注图像中的细节信息，提取更具鉴别性的特征。在提取特征图后，采用广义平均池化，然后水平均匀切分成若干块，进行局部特征学习。

 

最后，为了对网络进行端到端训练，联合使用分布一致性损失、三元组损失和身份损失。





# 方法

## 网络总体架构

本文的网络总体结构如下图1所示。首先，可见光图像和红外图像被输入至辅助模态生成器，用于生成辅助模态图像。然后，辅助模态图像和原始图像一同输入主干网络，以提取模态共享特征。主干网络前面的网络层参数是独立的，用于提取模态特定特征，而后面的网络层参数是共享的，用于提取模态共享特征。在第三个残差块之后，嵌入混合注意力引导学习模块，该模块旨在有效缓解模态间的差异，同时充分挖掘具有鉴别性的模态共享特征。在主干网络提取特征图后，将特征图水平划分成若干个部分，进行局部特征学习。最后，联合使用分布一致性损失、三元组损失和身份损失来对模型进行端到端训练网络架构可以有效解决跨模态行人重识别问题，并提高模型性能和泛化能力。





## 辅助模态生成器

辅助模态生成器采用编码器-解码器架构，其主要功能是将可见光图像和红外图像映射到一个统一的辅助模态空间，以生成辅助模态图像。这样生成的辅助模态图像有效地缓解了可见光模态和红外模态之间的模态差异。具体而言，辅助模态生成器由两个参数独立的编码器和一个参数共享的解码器组成。

首先，输入图像的尺寸被调整为3x384x192。由于红外图像是单通道的，而可见光图像是三通道的，因此需要将红外图像的通道数设置为3，以与可见光图像的通道数保持一致。

然后，可见光图像和红外图像分别输入对应的模态信息编码器进行编码。在编码过程中，首先通过一个卷积核为3x1x1的卷积层，将三通道图像转换为单通道图像。接着，通过卷积核为1x1x1的卷积层以减少计算量，并最后通过批归一化层进行数据归一化。

随后，归一化后的数据输入至对应的解码器进行解码。解码器将编码后的单通道图像通过卷积核为1x1x1的卷积层转换为三通道图像，从而生成对应的辅助模态图像。

总之，辅助模态生成器的编码器-解码器架构能够将可见光图像和红外图像转换为辅助模态图像，从而缓解模态间的差异，为后续模态共享特征的提取提供了有益的辅助。



## 混合注意力引导学习模块

本文中设计了一个混合注意力引导学习模块，该模块旨在有效减缓模态间的差异，并充分挖掘不同行人图像之间的细微信息。



混合注意力引导学习模块采用实例归一化[13]来缓解模态之间的差异，并结合了卷积注意力模块（Convolutional Block Attention Module，CBAM）[12]来引导模型关注特征图中的有效信息，挖掘不同行人图像之间的微妙差异。该模块的计算公式如下：

X = M(F) ⊗ F + [1 - M(F̅)] ⊗ F̅

其中，X表示经过该混合注意力引导学习模块输出的特征图，F表示输入的特征，F̅表示F经过实例归一化后的输出，M(F)表示特征F经过CBAM模块后得到的混合注意力掩码。

在这个公式中，混合注意力掩码M(F)和实例归一化后的特征图F̅结合在一起，通过元素级的加权求和来获得最终的输出特征图X。混合注意力掩码M(F)用来加权特征F中的各个通道，以提取重要的特征信息。而实例归一化后的特征图F̅可以进一步减少模态间的差异，提高特征的一致性和稳定性。

通过这样的设计，混合注意力引导学习模块可以同时发挥实例归一化和卷积注意力机制的作用，有效地减缓模态间的差异，并引导模型聚焦在关键细节上，从而更好地挖掘行人图像之间的微妙差异。这有助于提高跨模态行人重识别任务的性能。







混合注意力引导学习模块采用了实例归一化[13]来减缓模态间的差异，同时结合了卷积注意力模块（Convolutional Block Attention Module，CBAM）[12]来引导模型关注特征图中的有效信息，并发掘不同行人图像之间的微妙差异。该模块的计算公式如下所示：

X = M(F) ⊗ F + [1 - M(F̅)] ⊗ F̅

其中，X表示经过该混合注意力引导学习模块输出的特征图，F表示输入的特征，F̅表示F经过实例归一化后的输出，M(F)表示特征F经过CBAM模块后得到的混合注意力掩码。

具体而言，CBAM模块通过通道注意力和空间注意力引导模型关注重要的通道信息和空间信息。在通道注意力中，特征经过平均池化和最大池化后，通过共享的多层感知机MLP网络得到通道注意力特征图M_c (F)，它表示哪个通道的内容更重要。然后，M_c (F)与输入特征F相乘得到新特征F'，进一步输入至空间注意力模块。在空间注意力中，通过卷积运算得到空间注意力特征图M_S (F^')，它表示哪些区域更重要。最终，M(F)是通过将通道注意力和空间注意力相乘得到的。

实例归一化的计算公式如下所示：

F̅_i = (F_i - E(F_i)) / √(Var(F_i) + α)

其中，F̅_i表示输入特征F的第i维，E(·)和Var(·)表示计算每个维度的均值和标准差，α用于避免分母为零。

综上所述，混合注意力引导学习模块结合实例归一化和CBAM，有助于缓解模态间的差异，并引导模型关注重要的特征信息，从而发掘不同行人图像之间的微妙差异，提升跨模态行人重识别任务的性能。





## 损失函数

本文采用联合损失函数来优化训练模型，以扩大类间距离和提高类内不同模态特征相似度。联合损失函数包括分布一致性损失函数（L_dcl）、身份损失函数（L_id）和三元组损失函数（L_tri）。

1. 分布一致性损失函数（L_dcl）用于优化辅助模态生成器，生成更好的辅助模态图像。它通过计算辅助模态图像的特征向量之间的差异，来衡量生成的辅助模态图像的质量。具体计算公式如下：

L_dcl = 1/N ∑(i=1)^N mean[f(I_VtA^i) - f(I_ItA^i)]

其中，N是每一批次的训练样本总数。I_VtA和I_ItA分别表示由可见光图像和红外图像生成的辅助模态图像。f(·)表示辅助模态图像经过全连接层后的输出。mean[·]表示取均值。

1. 身份损失函数（L_id）用于进行交叉熵损失，帮助模型对不同身份的行人进行分类。具体计算公式如下：

L_id = ∑(i=1)^N [-qi log(pi)]

其中，N表示训练过程中的行人身份个数，y表示图像的行人身份标签。qi表示预测是类别i的可能性，pi表示真实类别i的概率。λ是一个常量，这里设置为0.1。

1. 三元组损失函数（L_tri）用于拉近不同模态相同身份的行人特征间的距离，推远相同模态不同身份的行人特征间的距离。具体计算公式如下：

对于可见光图像I_VIS和红外图像I_IR的三元组损失函数：

其中，N表示每种模态图像在一批次的训练样本中的数量总和，d(·)表示欧式距离，α是一个阈值常量，这里设置为0.3。其他模态间的三元组损失和上述定义的公式类似。

通过联合使用这三个损失函数，本文旨在实现模态间的特征优化，扩大类间距离，同时增强类内不同模态特征的相似性，从而提高跨模态行人重识别任务的性能。



Cross entropy loss function



# 实验

本文采用两个公开的可见光-红外行人重识别数据集SYSU-MM01和RegDB进行实验评估。

1. SYSU-MM01数据集：
   - 数据集由四个可见光相机和两个红外相机拍摄收集，包含491个行人身份，共有287628张可见光图像和15792张近红外图像，涵盖室内和室外环境。
   - 训练集包含395个行人身份，共有19659张可见光图像和12792张红外图像。
   - 测试集包含96个行人身份，其中有3803张红外图像作为查询图像。
   - 图库集根据测试模式分为全局搜索模式和室内搜索模式。在全局搜索模式下，所有由可见光摄像头拍摄的图像构成图库集。在室内搜索模式下，仅使用两个室内可见光摄像头拍摄的图像构成图库集。
2. RegDB数据集：
   - 数据集包含412个行人身份，由一个可见光摄像头和一个红外摄像头拍摄收集，每个行人身份有10张可见光图像和10张红外图像。
   - 数据集被随机分为两半：206个行人身份的图像用于训练，另外的206个行人身份的图像用于测试。
   - 测试有两种评估模式，分别是用可见光图像查询红外图像和用红外图像查询可见光图像。

在实验评估过程中，本文使用累积匹配特征（cumulative matching characteristics, CMC）和平均精度（mean average precision, mAP）作为模型性能的评估指标。CMC用于衡量模型在不同排名下的识别准确率，而mAP用于综合考虑检索精度和排名的平均性能。

通过在这两个数据集上进行实验评估，本文旨在验证所提出的方法在不同数据集和不同评估模式下的性能表现，以及其在跨模态行人重识别任务中的有效性和优越性。




本文采用了两个公开的可见光-红外行人重识别数据集，分别是SYSU-MM01和RegDB。SYSU-MM01数据集包含491个行人身份，其中包括287628张可见光图像和15792张近红外图像，涵盖了室内和室外环境。训练集有395个行人身份，共有19659张可见光图像和12792张红外图像。测试集包含96个行人身份，其中包含3803张红外图像作为查询图像。测试时，图库集根据全局搜索模式和室内搜索模式进行划分。

而RegDB数据集则包含412个行人身份，每个身份有10张可见光图像和10张红外图像。数据集被随机分为两半，206个行人身份的图像用于训练，另外的206个行人身份的图像用于测试。测试时，可见光图像和红外图像分别用于查询对方图像。

在实验评估过程中，本文使用累积匹配特征（CMC）和平均精度（mAP）作为评估指标。CMC用于衡量模型在不同排名下的识别准确率，而mAP则综合考虑检索精度和排名的平均性能。

通过在这两个数据集上进行实验，本文旨在验证所提出的方法在不同数据集和评估模式下的性能表现，以及其在跨模态行人重识别任务中的有效性和优越性。这些实验结果将有助于评估模型的稳健性和泛化能力，以进一步推进跨模态行人重识别领域的研究



## 实验细节

在本文的实验中，使用了PyTorch环境进行模型训练，总共进行了80个Epoch的训练过程。输入图像的尺寸被调整为3×384×192，并在训练阶段采用了随机水平翻转和随机擦除等数据增强技术，以增加数据的多样性和泛化能力。

在训练过程中，采用了warm-up策略来平滑训练梯度，初始学习率设置为1×10^(-2)，经过10个epoch线性增加到1×10^(-1)，然后在第20个epoch时将学习率衰减为1×10^(-2)，最后在第60个epoch时进一步衰减至1×10^(-3)。通过这样的学习率调整策略，有助于优化算法在训练初期更加稳定，而在训练后期能够更好地细化参数。

每个批次的训练样本由随机选择的4个行人组成，每个行人分别选择4张可见光图像和4张红外图像进行训练，以增加数据样本的多样性和复杂性，提高模型的鲁棒性。

在优化过程中，使用了SGD（随机梯度下降）优化器，并设置了动量参数为0.9，以加速训练过程并增加收敛性。

本文中还采用了三元组损失函数和分布一致性损失函数联合训练模型。三元组损失函数的边距超参数设置为0.3，而权重超参数设置为1，用于拉近不同模态相同身份的行人特征间的距离，推远相同模态不同身份的行人特征间的距离。分布一致性损失函数的权重超参数设置为0.5，用于优化辅助模态生成器，生成更好的辅助模态图像，以减缓模态间的差异。

通过以上实验设置和优化策略，本文旨在充分挖掘不同模态图像间的特征信息，提高模型在跨模态行人重识别任务中的性能和泛化能力。



## 实验结果

根据表1的实验结果，可以得出本文所提出的方法在跨模态行人重识别任务中表现出不错的性能效果。具体而言，相较于基于模态共享特征提取的CM-NAS方法，在SYSU-MM01数据集的all-search模式下，本文方法的Rank-1指标提升了5.09%，mAP提升了3.91%。在in-door模式下，Rank-1指标提升了5.41%，mAP提升了4.52%。在RegDB数据集的可见光图像检索红外图像的测试模式下，本文方法的Rank-1指标提升了9.04%，mAP提升了5.32%。在红外图像检索可见光图像的测试模式下，本文方法的Rank-1指标提升了5.78%，mAP提升了2.87%。

此外，与基于模态特定信息补偿的FMCnet方法相比，在SYSU-MM01数据集的in-door模式下，本文方法的Rank-1指标提升了4.27%，mAP提升了3.38%。在RegDB数据集的可见光图像检索红外图像的测试模式下，本文方法的Rank-1指标提升了2.72%。

综合来看，本文方法在两个公开数据集上都取得了显著的性能提升，特别是在SYSU-MM01数据集的in-door模式和RegDB数据集的可见光图像检索红外图像测试模式下，表现出更加优越的行人重识别性能。这表明本文所提方法能够更有效地处理模态差异，挖掘更具鉴别性的特征信息，提高了跨模态行人重识别的准确性和鲁棒性。



### 消融实验

在本文的SYSU-MM01数据集的all-search模式下，进行了对辅助模态生成器和混合注意力引导学习模块的消融实验，并将结果列在表2中。从表2中可以得知，辅助模态生成器和混合注意力引导学习模块能够有效地提升模型的性能。

具体来看，在基线模型中，Rank-1和mAP值分别为58.66和53.76。加入混合注意力引导学习模块后，Rank-1和mAP值分别提高到了62.40和58.44。在此基础上再加入辅助模态生成器，Rank-1和mAP值进一步提高到了67.08和63.93。

这些结果表明，混合注意力引导学习模块的引入可以显著提升模型的性能，它能够帮助模型更好地学习到不同行人图像之间的细微差异信息。同时，辅助模态生成器的加入进一步增强了模型的表达能力，通过生成辅助模态图像来缓解可见光和红外图像之间的模态差异，进一步提高了模型的性能。综合来看，辅助模态生成器和混合注意力引导学习模块的联合使用可以有效地提升跨模态行人重识别任务的性能，使得模型在图像匹配和检索方面表现更为优越





# 结论

本文针对跨模态行人重识别问题，设计了一个基于辅助模态生成器和混合注意力的双流参数共享网络。该网络在Resnet50的基础上进行改进，主要包括以下步骤：

1. 辅助模态生成器：首先，将可见光图像和红外图像输入至辅助模态生成器，通过编码器-解码器架构将它们投影到一个统一的辅助模态空间，生成对应的辅助模态图像。这些辅助模态图像有助于缓解可见光和红外图像之间的模态差异，使得模型能更好地理解图像间的细微差异。
2. 主干网络：辅助模态图像和原始图像一同输入至主干网络，其中前层网络层的参数用于提取模态特定特征，后面网络层的参数用于提取模态共享特征。主干网络嵌入混合注意力引导学习模块，该模块结合了实例归一化和卷积注意力模块，能够排除背景噪声的干扰，引导模型关注图像中的有效信息，充分挖掘不同行人图像间的细微差异。
3. 局部特征学习：在主干网络提取特征图后，将特征图水平均匀切分成若干块，进行局部特征学习。这样的设计有助于捕获更具鉴别性的局部特征信息，提高模型的鲁棒性。
4. 联合优化：最后，采用分布一致性损失、三元组损失和身份损失三种损失函数对网络进行端到端训练。分布一致性损失用于优化辅助模态生成器，三元组损失用于拉近相同身份的行人特征距离，推远不同身份的行人特征距离，身份损失用于确保提取的特征具有良好的身份鉴别性。

实验证明，本文所提方法在跨模态行人重识别任务上取得了显著的性能提升。与基于模态共享特征提取的方法和基于模态特定信息补偿的方法相比，本文方法在不同数据集上均取得了优越的性能，证明了其有效性和鲁棒性。整体而言，本文方法为解决跨模态行人重识别问题提供了一种可行且高效的解决方案。





本文提出了一个基于辅助模态生成器和混合注意力的双流参数共享网络，用于解决跨模态行人重识别问题。该网络通过辅助模态生成器将可见光图像和红外图像投影到统一的辅助模态空间，生成辅助模态图像，并与原始图像一起输入主干网络进行特征提取。混合注意力引导学习模块有效减缓模态间差异，并挖掘细微的特征信息。局部特征学习进一步提高鉴别性和鲁棒性。最后，通过联合优化分布一致性损失、三元组损失和身份损失，达到优化训练目的。实验证明，该方法在多个数据集上表现出色，超过了其他基准方法，为跨模态行人重识别任务提供了有效解决方案。
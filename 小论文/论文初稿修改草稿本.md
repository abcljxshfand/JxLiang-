# 论文初稿修改草稿本



# MMN

辅助模态生成器

在本文中，我们从以下两个角度解决这个问题：（a）我们引入非线性网络来减轻可见光和红外图像之间的模态差异； （b）我们将可见光和红外图像投影到统一的中间模态图像（UMMI）空间中，以帮助减少它们之间的模态差异。

基于上述目标，我们设计了一个非线性中间模态生成器（MMG），它分别用两个非线性编码器对可见光和红外图像进行编码，**然后通过两个参数共享模态解码器将它们投影到UMMI空间中，使得生成的中间模态（M-modality）图像具有统一的中间模态。因此，它极大地减轻了可见光和红外图像之间的模态差异**。所提出的方法通过易于实现的轻量级网络减少了模态差异，同时通过使用标准交叉熵损失和三元组损失保持身份间判别力[14]。此外，为了进一步减少从 VIS 和 IR 图像生成的 M 模态图像的差异，我们提出了分布一致性损失（DCL），以最小化从 VIS 和 IR 图像生成的 M 模态图像之间的距离。受到 PCB [30] 在有效提取判别特征方面工作的启发，我们还用它来提高我们方法的性能。通过将 MMG、DCL 和 PCB 纳入端到端学习框架，所提出的方法在两个具有挑战性的 VI-ReID 数据集上取得了令人印象深刻的性能



本文的主要贡献可以概括如下：（1）我们提出了一种非线性中间模态生成器来生成中间模态图像以辅助 VI-ReID 任务。特别是，所提出的中间模态生成器可以有效地将可见光和红外图像投影到统一的中间模态图像空间中。

（2）我们提出了一种有效的分布一致性损失，使得从VIS和IR图像获得的两类中模态图像在UMMI空间中的模态分布一致，这进一步提高了该方法的性能。

(3) 大量实验表明，所提出的方法在 SYSUMM01 和 RegDB 数据集上均显着优于其他竞争方法。



**摘要**

可见红外行人重新识别（VI-ReID）旨在跨不同光谱搜索行人的身份。在这项任务中，主要挑战之一是可见光 (VIS) 和红外 (IR) 图像之间的模态差异。一些最先进的方法尝试设计复杂的网络或生成方法来减轻模态差异，同时忽略 VIS 和 IR 两种模态之间的高度非线性关系。在本文中，我们提出了一种非线性中间模态生成器（MMG），这有助于减少模态差异。我们的MMG可以有效地将可见光和红外图像投影到统一的中间模态图像（UMMI）空间中，以生成中间模态（M-modality）图像。

生成的 M 模态图像和原始图像被输入骨干网络以减少模态差异。

此外，为了将 UMMI 空间中的 VIS 和 IR 图像生成的两种类型的 M 模态图像结合在一起，我们提出了分布一致性损失（DCL），以使生成的 M 模态图像的模态分布一致尽可能。最后，我们提出了一种中间模态网络（MMN），以显式的方式进一步增强特征的辨别力和丰富性。我们进行了大量的实验，以验证 MMN 在两个具有挑战性的数据集上的 VI-ReID 相对于一些最先进方法的优越性。即使与 SYSUMM01 数据集上最新的最先进方法相比，MMN 在 Rank-1 和 mAP 方面的增益也分别超过 11.1% 和 8.4%



**总结**

在本文中，我们提出了一种非线性中间模态生成器，这有助于减少可见光和红外图像之间的模态差异。所提出的中间模态生成器可以有效地将可见光和红外图像投影到统一的中间模态图像空间中以生成M模态图像。生成的多模态图像和原始图像被馈送到主干网络中以减少模态差异。此外，为了将 VIS 和 IR 图像生成的 M 模态图像结合在一起，我们提出了分布一致性损失，以使生成的 M 模态图像的模态分布尽可能一致。最后，我们提出了一个中间模态网络，以显式的方式进一步增强特征的辨别力和丰富性。大量的实验证明了所提出的中间模态网络与最先进的方法相比具有优越的性能



# MPA

**由于红外图像中隐藏的有效信息未被发现，现有方法在学习不同模态的判别特征方面的能力仍然有限**。在跨模态行人重识别中，不同图像对中的细微差别以各种模式出现，例如 T 恤和裤子的长度、鞋子的类型以及是否戴眼镜。如果这个信息没有被很好地发现，红外特征的辨别能力将比可见光特征差，如图1（c）所示。发现细微差别，同时减少模态差异，在可见红外人员重新识别中发挥着重要作用。最近提出了相当多的细粒度人员重新识别方法[15、24、27、36、40、43]，它们主要将身份分类、人员辅助信息整合到一个框架中来考虑人员的细节。然而，这些方法需要额外的标记先验，例如属性、关键点和人类解析信息，寻找某些部分并平等地对待这些部分，而不是自适应地选择它们。

由于缺乏必要的信息和模态的变化，这些方法无法在跨模态设置中学习判别性特征。因此，发现现有方法中未充分利用的细微差别自然可以提高特征的辨别力。



为了充分探索细微差别的信息，我们提出了一种新颖的跨模态行人重识别框架，称为联合模态和模式对齐网络（MPANet），它发现跨模态的细微差别，同时减轻可见红外行人重识别的模态差异。

如图 2 所示，所提出的 MPANet 框架由两个用于缓解模态差异的模态缓解模块（MAM）、一个用于发现不同模式中的细微差别的模式对齐模块（PAM）以及用于训练模型的相互均值学习方式组成。用于身份识别的中心簇损失和交叉熵损失。

具体来说，MAM 使用实例标准化来减轻模态差异，同时保持一定程度的区分性。通过轻量级生成器，图案对齐模块生成一组图案图，这些图案图关注不同的图案以发现细微差别。该模块的输出是通过连接模式特征和全局特征获得的。为了以无监督的方式发现细微差别，设计了区域分离约束以确保每个模式图关注不同的模式。然后提出中心簇损失来减少相同身份的某些模式特征之间的距离，同时增加不同身份的特征中心之间的距离。我们进一步应用两个特定于模态的分类器来学习每个模态的特征的身份，并用它们预测相同特征的分类结果。此外，通过减少不同模态特定分类器以相互平均学习方式生成的同一图像的预测之间的分布差异，减轻了模态差异。最后，将这两个模块以端到端的方式级联并联合优化。通过上述工作，MPANet 提取的特征是模态不变的，可以表示不同模式中的细微差别。





我们的主要贡献总结如下： • 我们在统一框架中解决了可见红外行人重识别的细微差别发现和模式差异。前者在文献中没有探讨，而后者是跨模式匹配人的关键。

• 为了发现细微差别并提取判别性特征，提出了模式对齐模块（PAM），以无监督的方式发现不同模式中的细微差别，并提出中心簇损失和分离损失。

• 为了在保留身份信息的同时减轻模态差异，提出了模态减轻模块（MAM），该模块在相互均值学习方式的指导下选择性地应用实例归一化。



总结

在本文中，我们提出了联合模态和模式对齐网络（称为 MPANet），以发现可见光-红外行人 Re-ID 的跨模态细微差别。我们的方法旨在减轻模态差异并发现不同模式中的细微差别，这是解决此任务的关键。为此，所提出的 MPANet 侧重于提取与模态无关的特征，特别关注身份之间的身份感知细微差别。**具体来说，MPANet 首先采用两个模态减轻模块 (MAM)，有选择地应用实例归一化来减轻模态差异，同时保留身份信息。然后，在模式对齐模块（PAM）中，根据模式图将特征图拆分为多个模式，从每个模式中提取特征以发现细微差别。**我们以端到端的方式优化 MPANet，其中相互均值学习方式充当跨模态差异约束。提出中心簇损失来学习细微差别信息并指导类级别的身份学习。两个公共数据集 SYSU-MM01 和 RegDB 上的实验结果充分证明对于发现跨模态检索问题中的跨模态细微差别以及证明 MPANet 对于可见红外行人重新识别的有效性至关重要。





摘要

可见光-红外行人重识别（Re-ID）旨在匹配来自不同模态的相同身份的行人图像。现有的工作主要集中在通过对齐不同模态的特征分布来减轻模态差异。然而，诸如眼镜、鞋子和衣服长度等细微但有区别的信息尚未得到充分探索，特别是在红外模式中。在不发现细微差别的情况下，仅使用模态对齐来匹配跨模态的行人是一项挑战，这不可避免地会降低特征的独特性。在本文中，我们提出了一种联合模态和模式对齐网络（MPANet）来发现可见红外行人重新识别的不同模式中的跨模态细微差别，该网络引入了模态缓解模块和模式对齐模块来联合提取判别特征。具体来说，我们首先提出一个模态减轻模块，以从提取的特征图中去除模态信息。然后，我们设计了一个模式对齐模块，它为一个人的不同模式生成多个模式图，以发现细微差别。最后，我们引入了一种相互均值学习方式来减轻模态差异，并提出了一种中心簇损失来指导身份学习和细微差别发现。对公共 SYSU-MM01 和 RegDB 数据集的大量实验证明了 MPANet 相对于最先进技术的优越性。



# 改进MMN



跨模态行人重识别任务的挑战在于摄像机角度差异导致不同摄像机获取的行人图像的特征（例如背景和姿势）显着变化，从而导致同一人之间存在类内差异。此外，可见光和红外相机的不同成像原理导致可见光和红外图像之间存在模态差异，这给跨模态行人重识别带来了巨大的挑战。

为了解决上述问题，Wu等人[3]提出了第一个跨模态行人重识别数据集——SYSU-MM01，其中包含多个场景、不同角度的行人图像，使模型能够学习各种不同的行人图像。背景和姿势，从而提高模型泛化能力。 Zhu等人[4]设计了异构中心损失（HC）以减少不同模态之间的类内中心距离。随后，Liu等人[5]在TriHard损失的基础上设计了异中心三元组损失（HcTri），通过用样本锚点中心之间的距离代替样本锚点之间的距离来弱化传统三元组的强约束。 Ye等人[6]使用Two Stream提取不同模态差异的特征，并将两种不同模态的特征映射到统一的空间进行度量学习。然而，该方法更关注图像背景，无法解决模态差异问题。为了进一步减少可见光和红外图像之间的模态差异，Liu等人[5]探索了具有参数共享的双流结构，并证明了参数共享对跨模态行人重识别的影响。 Dai等人[7]和Wang等人[8]使用生成对抗网络（GAN）将VIS图像生成相应的IR图像，并对原始IR图像进行特征提取，使得生成的IR图像减少了模态差异图像和特征级别。然而，由于非线性关系，GAN 方法无法在不改变人的身份的情况下完全从一种模态生成另一种模态的图像。 Li等人[9]提出了两种模态之间的X模态，它保留了源图像的空间信息，但X模态和红外图像之间仍然存在模态差异。

张等人[10]提出了一种中间模态生成器（MMG），它将可见光和红外图像映射到公共空间以生成相应的中间模态图像，进一步减少模态差异并提高模型的性能。



这些问题，例如可见光和红外图像之间的模态差异和类内差异，都得到了进一步解决。在本文中，我们对MMN[10]进行了改进，提出了一种基于联合中间模态和表示学习的跨模态行人重识别方法。本文的主要工作可以概括如下：（1）我们使用MMG通过将VIS和IR图像投影到统一的特征空间来生成中间模态图像，然后将中间模态图像和原始图像联合输入到两个特征空间中。 -用于特征提取的流参数共享网络，以减少模态差异。

（2）我们使用结合全局和局部特征的多粒度池化策略来提高模型的表征学习能力。

（3）通过结合分布一致性损失、标签平滑交叉熵损失和异中心三元组损失来联合优化模型，以减少类内距离并加速模型收敛。





本文首先介绍了行人重识别的研究背景和意义。然后，分别介绍了单模态和跨模态行人重识别的研究现状。然后，介绍了一种基于联合中间模态和表示学习的跨模态行人重识别方法，并详细阐述了中间模态生成器、双流参数共享网络、多粒度池化策略和联合损失。最后，在每个模块的两个公开数据集上进行消融实验，以验证每个模块的有效性。然后通过与主流方法的比较来证明所提出方法的优点。





在本文中，**我们使用ResNet50作为具有参数共享的双流网络的基础网络[5]**，并且ResNet50的第一个卷积层和前两个残差块作为特征提取器来提取每个模态的独立特征，最后两个残差块作为特征嵌入器进行权重共享，以进一步减少模态差异。

（3）多粒度池化（MGP）策略结合全局特征和局部特征，增强特征之间的相关性；池化方法采用广义均值池化（GeM），更加关注图像细节信息，提高模型的表示学习能力。

（4）本文结合分布式一致性损失[10]、标签平滑交叉熵损失[22]和异中心三元组损失[5]来优化模型并减少类内距离。





**总结**

在本文中，我们使用ResNet50作为具有参数共享的双流网络的基础网络[5]，并且ResNet50的第一个卷积层和前两个残差块作为特征提取器来提取每个模态的独立特征，最后两个残差块作为特征嵌入器进行权重共享，以进一步减少模态差异。然后采用结合全局和局部特征的多粒度池化策略来提高模型的表示学习能力，有效减少模态差异。还使用异中心三元组损失来减少类内差异，然后将其与分布一致性损失和标签平滑交叉熵损失相结合来共同优化模型。在公开的数据集上进行了大量的实验，本文提出的方法与现有的最先进（SOTA）方法相比具有更好的性能。





# 师姐

结论

针对跨模态行人重识别问题，本文提出了基于辅助模态和注意力机制的双流跨模态行人重识别算法。在训练模型的时候加入辅助模态，促使模型在提取可见光图像特征时不会过多注意颜色信息，缩小两个模态之间的差异。考虑到局部特征对于空间信息的确实，在双流网络中融入多头注意力机制，增强模型对空间信息的提取。最后使用身份损失和异质中心损失联合训练模型，增大类间距离，提高类内两个模态特征相似度，实验结果表明了该算法的有效性。



摘要

现有的跨模态行人重识别方法大多选择模态互转或直接将特征映射到共同特征空间，主要关注于缓解模态差异，而忽略同一模态下的类间差异，这不利于模型学习到具有辨别性的身份特征。本文提出一种基于改进的多头自注意力机制的非共享双流网络，分别提取可见光图像和红外图像的特征，并对特征做水平划分，使用局部特征来计算身份损失以及异质中心损失，利用多头自注意力机制根据像素本身的内容及其相对于相邻像素的空间位置来计算像素的注意力图，增强模型提取的信息容量，进而学习到同模态下不同类之间具有辨别性的身份特征。同时使用辅助模态来减缓可见光图像和红外图像在颜色信息上的差异，进一步减小模态差异。在SYSU-MM01和RegDB数据集上的mAP分别达到60.36%和76.10%，实验表明该方法的有效性。
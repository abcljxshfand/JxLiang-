# （华北电力大学）任欢-2021-（北大核心）注意力机制综述

![image-20221106105133271](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221106105133271.png)



## 摘要

**注意力机制的作用：**

注意力机制已广泛地应用在深度学习的诸多领域。基于注意力机制的结构模型**不仅能够记录信息间的位置关系，还能依据<font color='red'>信息的权重去度量不同信息特征的重要性（How？）</font>**。通过对信息特征进行相关与不相关的抉择建立动态权重参数，以**加强关键信息弱化无用信息**，从而提高深度学习算法效率同时也改进了传统深度学习的一些缺陷。



诸多领域：

图像处理、自然语言处理、数据预测



近几年大火的基于注意力机制的transformer和reformer算法进行了综述



## 引言

### 什么是注意力？

注意力是人类大脑中一项不可或缺的复杂认知功能，在日常生活中，人们通过视觉、听觉、触觉等方式接收大量的信息，但是人们在这些外界的信息轰炸中还能有条不紊地工作，是因为**人脑可以有意或无意地从这些大量输入信息中选择小部分的有用信息来重点处理，并忽略其他信息，这种能力叫作注意力。**

### 什么是注意力机制？

而注意力机制是自深度学习快速发展后广泛应用于自然语言处理、统计学习、图像检测、语音识别等领域的核心技术［6］。专家学者根据对人类注意力的研究，提出了注意力机制，本质上说就是**实现信息处理资源的高效分配**［7］。

当一个场景进入人类视野时，往往会先关注场景中的一些重点，如动态的点或者突兀的颜色，剩下的静态场景可能会被暂时性地忽略［8］。例如当人们需要寻找图片中的人物信息时，会更多地注意符合人物特征的图片区域，而忽略那些不符合人物特征的图片区域，这样就是注意力的合理有效分配。

### 注意力机制的作用？

注意力机制能够**以高权重去聚焦重要信息，以低权重去忽略不相关的信息，并且还可以不断调整权重，使得在不同的情况下也可以选取重要的信息，因此具有更高的可扩展性和鲁棒性**［9］。

此外，它还能通过共享重要信息（即选定的重要信息）与其他人进行信息交换，从而实现重要信息的传递［10］**<font color='red'>（注意力机制如何记录信息间的位置关系？）</font>**。

![image-20221129172330098](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221129172330098.png)

### 注意力机制在深度学习中能够发展迅速的原因

（1）这个结构是解决**多任务**最先进的模型，如机器翻译、问题回答、情绪分析、词性标记、对话系统、数据监测、故障诊断等［11-17］。

（2）注意力机制的显著优点就是**关注相关的信息而忽略不相关的信息**，不通过循环而直接建立**输入与输出之间的依赖关系**，并行化程度增强，运行速度有了很大提高［18-19］。

（3）它**克服了传统神经网络中的一些局限**，如随着输入长度增加系统的性能下降、输入顺序不合理导致系统的计算效率低下、系统缺乏对特征的提取和强化等。但是注意力机制能够很**好地建模具有可变长度的序列数据**，**进一步增强了其捕获远程依赖信息的能力，减少层次深度的同时有效提高精度<font color='red'>（How？）</font>**［9，20］。

[9] HAO S，LEE D-H，ZHAO D. Sequence to sequence learning with attention mechanism for short-term passenger flow prediction in large-scale metro system［J］. Transportation Research Part C： Emerging Technologies，2019，107：287-300.

[10] ZILLICH M， FRINTROP S， PIRRI F， et al Workshop on attention models in robotics：visual systems for better HRI［C］// Proceedings of the 2014 ACM/IEEE International Conference on Human-robot Interaction. New York：ACM，2014：499-500.

## 注意力机制前期应用

### 图像处理领域的应用

**作用：**

注意力机制的第一次提出是在视觉图像领域中［21］，它指出注意力的作用就是将之前传统的视觉搜索方法进行优化，可选择地调整视觉对网络的处理，减少了需要处理的样本数据并且增加了样本间的特征匹配。

**缺陷：**

文献［22］利用灵长类动物的视觉注意力提供了一个科学解释，提出的视觉注意模型结构比较简单，能够对接收到的信息进行特征提取并且快速检测出各种形状和颜色，**但是因为结构的简单，无法检测到特征间的相关性**，并且没有任何循环机制，所以在整个视觉识别过程中，无法重现图像轮廓

**RNN：**

循环神经网络框架（RNN）是由Jorden和Elman分别于1986年和1990年提出的，被认为是目前RNN的最基础版本，之后随着科技进步，问题复杂度的加深，RNN结构也在不断丰富和扩展［23］。循环神经网络，顾名思义其结构中含有循环层，而循环表示前一个和后一个是相关联的，即网络会对前面的信息进行记忆并作用于输出，这样神经网络中的隐藏层就存储了具有相关性的特征信息［24］，其结构如图2所示。

由图2可知，RNN下一时刻的输出与前面多个时刻的输入和自己当前状态有关，因此能够保留特征间的相关性，但是由于每一步状态的记录也会导致误差累积，从而有可能造成梯度爆炸；并且如果输入过多的序列信息，梯度的传递性不是很高，也会出现梯度消失的现象［24］。

![image-20221129213722788](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221129213722788.png)



**改进（与RNN结合）：**

人们就想到了将注意力机制与具有循环机制的循环神经网络（RNN）结合，并且在此基础上进行了一系列研究发现。

因此，Googlemind团队在2014年将循环神经网络（RNN）模型与attention机制结合［25］

利用注意力机制对特定的区域进行高分辨率处理。该模型受人类注意力的启发，根据需求将注意力集中在图片中特定的部分，类似于人类观察衣服图片时，往往不会看图片中所有因素，而是先注意到其中的突出因素。

所以基于任务需求，这个模型不是处理全部图像，而是有针对性地选择相应位置处理，使整个模型的性能提高。众多实验结果表明，基于注意力机制的循环神经网络可以比单纯的循环神经网络更好地处理一些杂波图像和像素比较大的图像，是因为它可以将需要处理的图像特征提取简化，从而缩短处理数据的时间并且保留重要信息。

**总结：**

将注意力机制与RNN结合，很好地解决了单纯使用RNN在图像处理中的局限，如处理繁琐的特征信息往往会因为层数过深而梯度爆炸。注意力机制巧妙地提取图像中的关键信息同时忽略无关信息，为数据处理提供了更多的便利，网络层数也不会过深，梯度爆炸的问题也得到了很好的解决。

### 自然语言处理领域的应用



### 数据预测领域的应用



## 注意力机制当前研究



## 注意力机制的应用展望



## 结语



------



## 理解

**1.引入：**

注意力是人类大脑中一项不可或缺的复杂认知功能，在日常生活中，人们通过视觉、听觉、触觉等方式接收大量的信息，但是人们在这些外界的信息轰炸中还能有条不紊地工作，是因为**人脑可以有意或无意地从这些大量输入信息中选择小部分的有用信息来重点处理，并忽略其他信息，这种能力叫作注意力。**

（总结：1.信息量大 ，包括了有用的信息、没用的信息。  22.人脑有意、无意对信息进行筛选。）

（举例子：很容易发现一群猴子中有一只大象、看图片、文章的时候会先关注某一部分）



**2.介绍**：

将注意力引入到我们的计算机领域，让计算机实现信息处理资源的高效分配。



**3.关键点**：

注意力机制能够**以高权重去聚焦重要信息，以低权重去忽略不相关的信息，并且还可以不断调整权重，使得在不同的情况下也可以选取重要的信息，因此具有更高的可扩展性和鲁棒性**。

此外，它还能通过共享重要信息（即选定的重要信息）与其他人进行信息交换，从而实现重要信息的传递。





![image-20221202151442089](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221202151442089.png)

## encoder-decoder框架

![image-20221130104112992](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221130104112992.png)

### **组成：**

encoder：文本处理和语音识别的encoder通常用RNN，图像处理的encoder一般采用CNN

语音编码c：

decoder：



### **举例子：**

![image-20221130104550839](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221130104550839.png)



### **分心模型：**

![image-20221130104753443](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221130104753443.png)



### **注意力机制：**

![image-20221130105112781](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221130105112781.png)

![image-20221130105221693](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221130105221693.png)

### **总结：**

输出Y1，Y2，Y3（完成某一项任务）的时候需要考虑输入X1、X2、X3、X4（输入的信息）的相关性，注意力机制可以帮助Y来选择有用的信息。在这个过程中，会生成c1、c2、c3（注意力分布）来“指导”Y的输出，告诉Y哪些信息是对你有用的，哪些信息是没用的。



**Attention机制的实质其实就是一个寻址（addressing）的过程**，如上图所示：给定一个和任务相关的查询**Query**向量 **q**，通过计算与**Key**的注意力分布并附加在**Value**上，从而计算**Attention Value**，这个过程实际上是**Attention机制缓解神经网络模型复杂度的体现**：不需要将所有的N个输入信息都输入到神经网络进行计算，只需要从X中选择一些和任务相关的信息输入给神经网络。

**注意力机制可以分为三步：一是信息输入；二是计算注意力分布α；三是根据注意力分布α 来计算输入信息的加权平均。**

![image-20221130112034431](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221130112034431.png)

## 本质思想

1.

![image-20221130192304054](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221130192304054.png)

![image-20221130192342356](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221130192342356.png)

2.

![image-20221130192435748](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221130192435748.png)



## Attention机制的具体计算过程

![image-20221130192543732](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221130192543732.png)

### 步骤

![image-20221130192610421](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221130192610421.png)

1.计算相关性（即F（Q，K），不同attention机制，往往采用不同的相关性计算方式），得到注意力得分，越相关，得分越高

![image-20221130192638776](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221130192638776.png)

![image-20221130192839365](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221130192839365.png)

2.得分归一化，得到权重系数

![image-20221130193439956](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221130193439956.png)

3.对Value加权求和

![image-20221130193528891](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221130193528891.png)

Value和Key的关系（在此例中相同）

![image-20221130193727028](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221130193727028.png)


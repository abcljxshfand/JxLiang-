# （厦门大学）Wu-2021-（CVPR）Discover Cross-Modality Nuances for Visible-Infrared Person Re-Identification

**2022.11.25：**

**（注：棕色标注表示我的一些疑问；黄色标注表示阅读文献时候的注意点，帮助我重新读的时候更快理解文章内容；绿色标注表示问题（研究目标、研究内容、关键问题），问题背景等；蓝色标注表示某项方法、行为的作用、目的、意义；红色标注表示我认为的重点，需要特别关注；紫色标注表示预备知识；）**

**（注：现阶段（基础），笔记主要围绕三点，1.知识体系结构  2.文章的诉求  3.文章的主要贡献、特点、创新点。）**

![image-20221106105213097](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221106105213097.png)

------

![image-20221125213154814](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221125213154814.png)

## 背景、目的与结论

**背景：**

在跨模态行人重识别任务中，最关键的是要解决模态间的差异。

不同图像对的细微差别出现在不同的模式中，例如T恤和裤子的长度、鞋子的类型以及是否戴眼镜。

尽管已经有了很多方法，并取得了一定的成效。但是对图像间的细微差异挖掘得不够充分，现有方法中学习到具有鉴别性的特征的能力仍有待提高。

（**注：**已经提出了相当多的细粒度的人重新识别方法[15，24，27，36，40，43]，它主要将身份分类、人辅助信息合并到一个框架中，以考虑人的细节。然而，这些方法需要额外的标记先验，例如属性、关键点和人类解析信息，寻找某些部分并平等对待这些部分，而不是自适应地选择它们。由于缺乏必要的信息和模态的变化，这些方法无法在跨模态环境中学习辨别特征。因此，发现现有方法中未充分利用的细微差别自然可以提高特征的辨别能力。）



**目的：**

设计一个模型，缓解模态间的差异，同时可以发现可见红外人物Re-ID的不同模式中的跨模态细微差别，提取出具有鉴别性的特征。



**结论：**

提出了一种**联合模态和模式对齐网络（a joint Modality and Pattern Alignment Network，MPANet）**来发现可见红外人物Re-ID的不同模式中的跨模态细微差别，该网络引入了模态减轻模块和模式对齐模块来联合提取辨别特征。

具体地，我们首先提出了一种**模态减轻模块（The Modality Alleviation Module，MAM）**，以从提取的特征图中去除模态信息。

然后，我们设计了一个**模式对齐模块（the Pattern Alignment Module，PAM）**，它为一个人的不同模式生成多个模式图，以发现细微差别。

最后，我们引入了**一种互均值学习方式（a mutual mean learning fashion ）**来缓解模态差异，并提出了一种**中心聚类损失（ the cross-entropy loss）**来指导**身份学习和细微差别发现（identity learning and nuances discovering）**。在公共SYSU-MM01和RegDB数据集上的大量实验表明MPANet优于现有技术。

## 结果与讨论

![image-20221125215455615](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221125215455615.png)



![image-20221125215517414](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221125215517414.png)

## 文章好在哪里

**主要贡献：**

1. 我们在统一的框架中解决了可见红外人员Re-ID的细微差别发现和模态差异。文献中没有对前者进行探讨，而后者是跨模式匹配人的关键。
2. 为了发现细微差别并提取辨别特征，提出了模式对齐模块（PAM），以无监督的方式发现不同模式中的细微差别，并提出了中心聚类损失和分离损失。
3. 为了在保持身份信息的同时缓解模态差异，提出了模态缓解模块（MAM），该模块在相互平均学习方式的指导下选择性地应用实例归一化。

## 自我想法
# (厦门大学)Yukang Zhang-2022-（顶刊）Towards a Unified Middle Modality Learning for Visible-Infrared Person Re-Identification

# 摘要

**问题：**



**<font color='red'>本文提出的方法：</font>**

**1.提出了一种非线性中间模态生成器 (MMG)，它有助于减少模态差异。**

我们的 MMG 可以有效地将 VIS 和 IR 图像投影到统一的中间模态图像 (UMMI) 空间中，以**<font color='red'>生成中间模态 (M-modality) 图像</font>**。



**2.为了将 UMMI 空间中的 VIS 和 IR 图像生成的两种类型的 M 模态图像放在一起，我们提出了分布一致性损失 (DCL) 以使生成的 M 模态图像的模态分布一致尽可能。**



**3.提出了一个中间模态网络 (MMN)，以显式方式进一步增强特征的辨别力和丰富度。**



# 引言

**背景介绍：**

通常，现有方法 [3、24、39、40] 估计一些嵌入函数，这些函数将可见光 (VIS) 和红外 (IR) 图像的输入映射到一个公共嵌入空间，这样跨模态检索任务就变成了 VIS - 欧氏空间中的 ReID 检索任务。

然而，**<font color='red'>（问题：）由于 VIS 和 IR 图像之间的模态差异是高度非线性的 [5, 20]，因此为 VI-ReID 构建通用表示空间具有挑战性</font>**，如图 1 所示。



VI-ReID 问题有两种流行的方法。例如，一些传统方法 [3, 7, 39, 40, 45] 试图找到一个特定的嵌入空间**（Feature Embeding）**，其中可以最小化不同模态之间的差异，**并没有考虑 VIS 和 IR 图像之间的非线性关系。**另一种方法是图像级方法（例如 [34-36]**（GAN）**，然而，这种策略需要复杂的生成网络和判别网络，**并且生成的图像与真实图像之间仍然存在差距。**





**本文使用的方法：**

**<font color='red'>解决思路：</font>**

a.我们引入了一个非线性网络来减轻 VIS 和 IR 图像之间的模态差异；

b.我们将 VIS 和 IR 图像投影到统一的中间模态图像 (UMMI) 空间中，以帮助减少它们之间的模态差异。



**<font color='red'>具体实现：</font>**

1.**设计了一个非线性中间模态生成器（MMG）**，它分别用两个非线性**编码器**对VIS和IR图像进行编码，然后通过两个参数共享模态**解码器**将它们投影到UMMI空间，使得生成的中间模态（M-modality）图像具有统一的中间模态。因此，它极大地减轻了 VIS 和 IR 图像之间的模态差异。



2.所提出的方法通过易于实现的轻量级网络减少了模态差异，同时通过使用标准交叉熵损失和三元组损失 [14] 保持身份间辨别力。此外，为了进一步减少从 VIS 和 IR 图像生成的 M 模态图像的差异，我们**提出了分布一致性损失 (DCL)** 以最小化从 VIS 和 IR 图像生成的 M 模态图像之间的距离。



3.受 PCB [30] 在有效提取判别特征方面的工作的启发，我们还使用它来提高我们方法的性能。**通过将 MMG、DCL 和 PCB 纳入端到端学习框架**，所提出的方法在两个具有挑战性的 VI-ReID 数据集上取得了令人印象深刻的性能。



# 方法

<font color='red'>**整体结构**：</font>

![image-20230607110730290](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20230607110730290.png)



1. 图 2 概述了所提出的 MMN 方法。 MMN 的输入是一对 VIS-IR 图像。 VIS 和 IR 图像被馈送到建议的 MMG 模块中以生成中间模态（M-模态）图像。
2. 生成的具有原始 VIS 和 IR 图像的 **M 模态图像**被送入双流 ResNet50 [13、45] 主干以提取模态不变特征其中每个流中的第一个卷积块不同以捕获模态特定低层表示，而共享中层和深层卷积块以学习模态共享的中层和深层表示。
3. 受 PCB [30] 在提取判别特征方面的工作的启发，它将特征图水平划分为几个部分，并将每个部分馈送到分类器中以学习局部线索，我们还使用它来提高所提出模型的性能和部分设置为 4。我们进一步将主干网络中最后一个卷积块的步幅修改为 1，以保留更多的空间信息 [30]。
4. 在具有平均池化 (AP) 层的卷积层之后，我们添加了一个批量归一化 (BN) 层，它在所有模态图像之间共享参数，以使损失更容易收敛 [25]。最后，将 BN 层前后的特征馈入不同的损失函数，共同优化网络。



## Middle Modality Generator (MMG)

![image-20230607152717612](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20230607152717612.png)

![image-20230607153948063](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20230607153948063.png)

![image-20230607153751248](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20230607153751248.png)

**输入：**

![image-20230607152836573](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20230607152836573.png)

I分别表示来自数据集的 VIS 和 IR 图像，对3×𝐻×𝑊分别对应通道、高度和权重。所有输入图像的大小都调整为 3 × 384 × 192，因此我们可以将 IR 图像视为三通道图像。实际上，它是一个只有一个通道的灰度图像。

![image-20230607152936637](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20230607152936637.png)

表示由I生成的中间中间模态图像对

**模型结构：**

**1.模态信息编码器 (MIE)**，它使用两个不共享参数的编码器对不同的模态信息进行编码，

**2.模态信息解码器 (MID)**，它使用两个共享参数的解码器将 VIS 和 IR 图像投影到 UMMI 空间




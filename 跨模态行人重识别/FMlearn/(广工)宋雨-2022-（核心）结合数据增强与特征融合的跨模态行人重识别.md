# (广工)宋雨-2022-（核心）结合数据增强与特征融合的跨模态行人重识别

**<font color='red'>现阶段重点是</font>**：

1.看看别人是怎么缝的（自己能不能借鉴） 

2.缝完是怎么吹的 

3.知道做到什么地步就可以发论文。



------

# 摘要

**存在问题：**

可见光-红外行人重识别问题的难点在于图像间模态差异大，

大多数现有的方法通过**生成对抗网络生成伪图像**或**提取原始图像上的模态共享特征**来**缓解模态差异**。

然而，训练**生成对抗网络需要消耗大量的计算资源**且生成的伪图像**容易引入噪声**，**提取模态共享特征**也会不可避免地导致与行人身份相关的**重要判别特征丢失**。





**解决方案：**

针对以上问题，提出新的跨模态行人重识别网络。

首先，将进行**自动数据增强后**的训练数据集作为网络输入，可以提高模型的鲁棒性；

然后，在网络中引入**实例正则化（改进残差块）**来缩小模态差异；

最后将网络各层提取到的**不同尺度的行人特征进行有机融合**，融合后的特征包含更多与行人身份相关的判别特征。



**结果**

提出的方法在**SYSU-MM01数据集**的全局搜索模式下**rank-1/mAP分别达到69.47%/65.05%**，在**RegDB数据集**的可见光到红外模式下r**ank-1/mAP分别达到85.73%/77.77%**，实验结果提升效果显著。





# 背景、研究目标、研究内容（引言）

## 背景

跨模态行人重识别面临一些挑战：

为了解决这些问题，人们提出了大量的方法，主要包括图像迁移和模态共享特征提取。

图像迁移旨在（...）来缓解模态差异，主要方法是（...），但是生成的伪图像不可靠，尤其是由红外图像生成可见光图像。同时高度依赖样本数据，因此不能适用于大规模的应用场景。

模态共享特征提取旨在通过（...）来缓解模态差异，这些方法主要是（...）。但是，会丢失一些重要的特征。同时，神经网络提取出来的特征不能充分描述行人信息。



## 研究目标和研究内容

通过分析现有方法的优缺点，本文在基准模型AGW的基础上进行了进一步的优化。

**<font color='red'>数据增强：</font>**<font color='blue'>由于跨模态行人重识别数据集单一</font>，本文采用**自动数据增强策略**丰富训练样本的多样性，**以提高模型的鲁棒性和泛化能力**。<font color='blue'>为了缩小模态差异</font>，本文联合像素级和特征级对**行人特征进行对齐**。首先将可见光图像进行灰度化，从视觉上使得可见光图像和红外图像更为相似，这可以拉近可见光图像和红外图像的特征分布。与生成对抗网络生成的伪灰度图不同，此处灰度图是由可见光图像三个通道的像素进行线性累加得到。**这种灰度化方法不会引入噪声且很好地保留了图像结构**。

**<font color='red'>改进残差块：</font>**其次，**在网络的残差块中使用实例正则化**。实例正则化<font color='blue'>可以消除图像风格（比如光照强度、颜色信息等）差异[13]</font>，这可以缩小模态差异，使得网络提取到更多与行人特征相关的信息。

**<font color='red'>特征融合：</font>**最后，<font color='blue'>为了解决行人信息丢失问题</font>，**本文将浅层网络提取到的细节信息与深层网络提取到的语义信息进行有机融合**，将融合后的特征作为网络的输出，融合后的特征包含了更多与行人身份相关的特征。与现有方法对比，所提方法在两个公开数据集SYSU-MM01和RegDB进行了大量实验，实验结果充分显示了其有效性和优越性。

# 方法介绍

![image-20230426205025402](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20230426205025402.png)

整体架构：整个网络以端到端的方式进行训练。模型主要由数据增强、双流输入、特征提取、分层特征融合和特征嵌入五部分组成。损失函数由三部分组成。




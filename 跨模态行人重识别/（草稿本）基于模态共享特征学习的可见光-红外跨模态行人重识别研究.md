# （草稿本）基于模态共享特征学习的可见光-红外跨模态行人重识别研究

## 总体思路

------

正道

1.这个故事（论文的研究问题）是有意义的（重要性，迫切性，研究背景与意义）

2.这个有意义的故事别人是没有说过的，或者是没有说好（找出别人的问题和存在空白，文献综述）

3.你准备怎么说这个故事？（故事怎么展开叙述？研究内容与方法） 

4.你怎么让人相信你可以说好这个故事呢？（前期基础，可行性分析）



------

邪道

![image-20221214154802954](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221214154802954.png)

![image-20221215105058711](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221215105058711.png)



![image-20221214154524425](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221214154524425.png)

![image-20221214194457672](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221214194457672.png)

![image-20221214151645758](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221214151645758.png)

------

我道

我要干嘛？在符合规则的情况下做好事情。

原封不动地照搬别人的东西不算创新，所谓复刻是指把别人的东西（存在的问题与解决方法）拿过来然后结合自己的实际情况进行修改。领域A有1个问题，别人是用a1方法解决，我把它复刻下来，存在A1问题，我用a1’方法解决了。例如西红柿炒鸡蛋，我用的是小番茄炒鸡蛋、加了味精

所谓堆叠是指把别人的想法（包括存在的问题与解决的思路）提取出来后，生成一个模块，这个模块（a+b+c）可以解决A、B、C等等的问题。

------



# 引言

**<font color='red'>举例子</font>**

![image-20221210110826006](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221210110826006.png)

研究对象是什么？股票市场联动性

引言第一段：我为什么要研究这个问题，这个问题在实际、理论方面的重要性是什么？第一个要解释的：股票。第二个：中美的联动，中国、美国，有很重要的意义

第二段：现有研究、存在问题（说别人的缺点）

第三段：我研究的内容，有什么优点

------

**第一段：关键词：行人重识别、可见光-红外跨模态行人重识别**

首先介绍行人重识别是什么，然后解释可见光-红外，可见光是什么，红外是什么，对我们的生活有哪些重要意义？



行人重识别（Person Re-Identification, re-id）

行人重识别（PersonRe-Identification,re-id）是指利用计算机视觉技术在指定视频或图片序列中对特定行人进行识别的技术，通常被认为是图像分类或图像检索的子问题。作为跨摄像头行人轨迹跟踪、行人行为识别等机器视觉方案的核心构成，行人重识别技术在园区安防、公安刑侦、交通纠违与公共安全等领域展现出广阔的应用前景。



程云舟

行人重识别[1],[2]是一项重要的图像分析技术，旨在解决不同摄像头之间的行人检索问题，由于其在智能视频监控领域中的重要性，受到了学术界和工业界越来越多研究者的关注。目前，大部分的行人重识别方法都集中在对可见光行人图像匹配问题的研究上，这是最常见的单模态行人重识别。例如图1-1所示，给定一张待查询图像，目标在由多个非重叠摄像机拍摄的候选图片集中匹配目标人物，进而能够确定该目标人物的行动轨迹。当然，在单模态行人重识别中，所有的行人图像均取自于工作在白天的可见光摄像头。

然而，在全天候智能监控系统中，只有可见光摄像头是远远不够的，特别是在弱光或无光（例如夜晚）的环境下，可见光摄像头并不能捕捉到有效的行人信息。为了解决这个问题，人们通常使用红外摄头或者能够切换到红外模式的摄像头进行拍摄。在这种情况下，若行人重识别过程中的查询图像是一张可见光（红外）图像，候选集中将会存在红外（可见光）图像。<font color='red'>相对于三通道的可见光图像，红外图像仅含有一个通道的图像信息可供利用。正是由于可见光图像和红外图像之间巨大的差异，导致了传统单模态下的行人重识别模型无法正常的工作。因此，跨模态行人重识别问题[3]被提出，</font>旨在解决基于红外图像和可见光图像之间互相检索的行人重识别问题。如图1-2所示，给定一张可见光行人图像，希望在红外图像所表示的候选集中检索出目标行人，或者给定的行人图像是红外图像，而候选集是由可见光模态的图像组成。由图中可以看到，尽管目标行人的着装具有很高的辨识度，这对于深度学习算法或者是我们人眼来说，都是极具判别性的特征，但是在进行跨模态行人重识别时却不能直接进行利用。



外文综述

行人重识别（ReID）是智能监控系统的关键技术之一，旨在通过一些不重叠的摄像头视图匹配感兴趣的人。由于监控视频分析需求的快速增长，近年来，ReID人获得了相当大的关注，<font color='red'>并在计算机视觉方面取得了越来越快的进展[1-3]</font>。然而，大多数现有模型主要关注单模态人ReID（VV-ReID），其仅涉及可见图像。不幸的是，这种技术在黑暗场景下的糟糕性能限制了其应用于24/7监控系统，在那里需要从白天到晚上的人员搜索。<font color='red'>与可见光相机相比，红外（IR）相机仍然可以在黑暗环境中从场景中捕获足够的信息[4]。</font>

此外，大多数监控系统通常使用双模摄像机，它们支持根据光线条件在可见模式和红外模式之间自动切换。因此，有必要研究跨模态人ReID（VI ReID），其中人搜索是在可见图像和红外图像之间进行的。



魏梓

随着人们对社会公共安全的日益关注，大量监控摄像头被部署在公共场所中以实现对高威胁人群的实时监测。行人重识别旨在利用计算机视觉技术在多个摄像头下检索特定的监控行人图像。近几年已有大量基于深度学习的方法在可见光行人重识别方向取得重大进展［１］。然而，现实中多数恶性事件易发生在夜间弱光条件下。为了保证对危险人员的全天时监控，红外摄像头被广泛应用于夜间场景中［２］，将其与可见光摄像头联合，可实现对危险人群的追踪与抓捕。如何从可见光（或红外）摄像头下检索红外（或可见光）摄像头下的特定行人图像，即跨模态行人重识别，对于我国安防智能化建设具有重要的研究意义。可见光与红外图像存在明显的差异：可见光图像为三通道图像，包含丰富的颜色信息；而红外图像为单通道灰度图像，缺少颜色信息。跨模态行人重识别的难点不仅体现在异质图像巨大的跨模态差异，也体现在相同模态不同摄像头下由于光线、视角变化引起的行人图像差异。



相旭

跨模态Re-ID算法可以在白天和夜晚两种模态间进行检索，可以应用在安防、监控、追踪等诸多领域，对保障人们的财产不受损害、保护人民生命安全以及提高社会稳定性有深远意义。跨模态Re-ID目前仍处于萌芽时期，许多相关算法并不能达到应用标准，但是跨模态Re-ID课题仍旧是现下的热点。、

**第二段**

现有研究、存在问题（说别人的缺点）



程云舟

跨模态行人重识别比单模态行人重识别面临着更为巨大的挑战，需要同时解决模态内行人图像的差异问题和模态间行人图像的差异问题。

模态内行人图像的差异主要是由于不同的行人姿态、背景以及摄像头视角等因素造成的，例如待查询图像行人的姿势是正面，而候选集当中的行人可能是侧面、背面，甚至是被障碍物遮挡的行人图像。模态间行人图像的差异主要是由于可见光摄像头和红外摄像头不同的成像原理造成的，红外摄像头对可见光不敏感，是通过红外线发射器发射的红外线（不可见光）进行成像。相比三通道的可见光图片，红外图片只有一个通道，丢失了颜色信息等重要行人重识别线索，因此可以认为二者为不同模态的数据。



外文综述

VI ReID的挑战主要在于两个方面：跨模态变化和模态内变化。可见光和红外图像之间的模态差异导致了跨模态变化。具体而言，如图2（b）所示，可见光和红外图像由于其不同的成像原理而本质上不同。

例如，可见图像通常有三个通道，包含丰富的视觉信息，如形状、位置、颜色和纹理。而红外图像具有一个通道，并且主要包含轮廓和位置信息。

跨模态变化对VI ReID产生了不利影响。

首先，如图3（a）所示，它将导致RGB模态和IR模态之间的不同特征分布，这进一步导致同一身份的不同模态之间的若干未对准问题。例如，这将使同一身份内的跨模态差异大于不同身份内的模态差异。其次，如图3（b）所示，它使更多的人歧视信息受到干扰。例如，在VV ReID中，颜色信息是识别不同人物的最重要的外观线索之一。然而，在VIReID中，几乎不能使用颜色信息。这意味着VI ReID任务中的有用信息远远少于VV ReID任务，这使得VI ReID更具挑战性。与VV ReID类似，VI ReID中的模态内变化也由视角、姿势和曝光中的人物变化引起。这进一步增加了VI ReID的难度。



# 文献综述

## 思路

分方面，找内容，再去综，最后加文献述评。

文献述评：现有文献有哪些方面存在不足，因此我要解决不足（关键！）对应你的研究内容、创新点

**分方面：**以某种逻辑（围绕题目）介绍出来。框架：1.拆分关键词  2.从大到小

举例子

![image-20221210203747782](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221210203747782.png)

CSR伪善性 、消费者、两者关系

![image-20221210203935057](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221210203935057.png)

消费者、女性消费行为、共享经济的行为

**再去综：**

1.

历史脉络：原始到新。如最具代表性，基础性的，然后在此基础上演化。在写的时候，强调历史演化性，后一篇文章相对于前一篇文章有哪些创新，罗列

2.

主题划分：对主题进行分类



**评述：**

两步走。1.研究问题的重要性，意义，有价值。2.但是已有研究存在一些不足（相对于我所研究的特定问题，我的创新点）



## 分方面

我的题目是基于模态共享特征学习的可见光-红外跨模态行人重识别，**我将采取从大到小：单模态行人重识别，再到跨模态行人重识别这样进行划分。**

然后再对这两个内容进行**更进一步细分（围绕我想用的方法——表征与度量、注意力机制、局部特征）**

单模态：（深度学习）表征【全局、局部、全局+局部】、度量

跨模态：（模态共享特征学习）表征（又或者称为特征投影）【多尺度特征、挖掘全局和局部信息、使用注意力机制、图卷积、优化BN层、优化分类器】、度量【identity loss、contrastive loss、triple loss、adversarial loss】、（模态信息补偿学习）单一转【】、互转【】

**（李文康）基于深度学习**

<font color='red'>单模态：增强模型特征提取能力、设计损失函数</font>

<font color='red'>跨模态：减少模态差异、设计度量损失函数</font>

![image-20221210205930542](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221210205930542.png)

单模态行人重识别（ReID）要解决的问题，可见光-红外光跨模态行人重识别（VIReID）也要解决。所以，本节将先介绍单模态行人重识别的研究现状，再介绍可见光-红外光跨模态行人重识别的研究现状。

行人重识别的基本解决方案是，将要检索的行人图像以及图库中的行人图像，一一映射成一维向量。再根据图库图像和检索图像向量间的余弦距离或欧几里得距离，将图库图像由小到大排序。距离越小，和检索图像间的相似度就越大。排好序的图像列表即为行人重识别的结果。为了提升行人重识别模型的效果，大多数工作从增强模型的特征提取能力和设计损失函数这两方面着手。



![image-20221210210051744](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221210210051744.png)

目前可见光-红外光跨模态行人重识别的研究方向主要有两种，一是减少可见光-红外光图像间的模态差异，二是设计适合跨模态的损失函数。





**外文综述**

![image-20221211105107076](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221211105107076.png)

如图4所示，<font color='red'>根据它们处理跨模态变化和模态内变化的方式，我们将这些模型分为四类，包括模态共享特征学习、模态特定信息补偿、辅助信息和数据增强。</font>如图4所示，基于模态共享特征学习的模型旨在提取那些有区别的模态共享特征，并丢弃那些模态特定特征，以同时解决VI ReID的跨模态变化和模态内变化。然而，如图4所示，基于模态特定信息补偿的模型首先通过使用一些生成模型（如生成对抗网络（GAN））从现有模态生成缺失模态，以减少跨模态变化。然后，他们从生成的原始信息中提取有区别的人物特征，以处理模态内变化。不同的是，基于辅助信息的模型试图使用一些辅助信息，例如一些人的面具和属性，以便于提取更有区别的人特征。除了那些广泛使用的数据增强策略，如随机调整大小、裁剪和水平翻转，基于数据增强的模型还试图开发一些专用的数据增强战略，以提取VI ReID网络中更多与人相关的特征。

如上所述，基于模态共享特征学习的模型旨在为VI ReID提取那些有区别的模态共享特征。<font color='red'>此外，根据它们提取模态共享特征的方法</font>，如图1所示，我们将这些现有的基于模态共享特征学习的模型进一步分类为三种类型，<font color='red'>即特征投影、特征解缠和度量学习</font>。

具体而言，如图5（a）所示，基<font color='red'>于特征投影的模型旨在首先将这些单模态特征投影到共享特征空间中，以解决跨模态变化。然后，他们在该特征空间中提取区分模态共享特征，以处理模态内变化。</font>如图5（b）所示，基于特征解缠的模型旨在首先设计ReID网络，该网络可以明确和直接地将单一模态特征解缠为模态特定特征和模态共享特征。然后，他们使用VI ReID的模态共享特征。不同的是，<font color='red'>基于度量学习的模型不侧重于优化网络结构，而是强调使用不同的损失函数或训练策略来优化学习过程，以便于为VI ReID提取更多与人相关的和模态共享的特征。</font>在以下内容中，我们将详细介绍三种基于模态共享特征学习的模型。



**（程云舟）基于特征融合和度量学习**

单模态：基于全局特征、基于局部特征、基于度量学习



**（相旭）基于模态对齐**

单模态：

![image-20221211103553520](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221211103553520.png)



**（叶茫）综述**

单模态：表征学习、度量学习、排序优化

## 再去综

有两种方式进行综合：1.以某种主题进行综合（概括该主题的特点）。2.以历史脉络进行综合（要介绍发展历程）。

### 单模态行人重识别

在行人重识别技术研究初期，所提出的方法主要集中在基于手工特征提取[6]等传统方法上，但随着深度学习的发展，行人重识别技术也发生了质的飞跃。它的技术路线（基本解决方案是：）。在本小节中，主要介绍基于深度学习的行人重识别方法，根据解决问题的思路，可以分为以下两种方法：表征学习和度量学习。

![image-20221211151808148](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221211151808148.png)

#### 表征学习

**（叶茫）外文综述**

旨在提取更具有鲁棒性的特征来帮助我们解决行人重识别问题，主要有两种方法：全局特征、局部特征。

我们首先讨论了封闭世界人Re-ID中的特征学习策略。有四个主要类别（如图2所示）：a）全局特征（§2.1.1），它为每个人图像提取全局特征表示向量，而无需额外的注释提示[55]；b） 局部特征（§2.1.2），它聚合部分级局部特征，以形成每个人物图像的组合表示[75]，[76]，[77]；c） 辅助特征（§2.1.3），它使用辅助信息改进了特征表示学习，例如属性[71]、[72]、[78]、GAN生成的图像[42]等。

d） 视频特征（§2.1.4），它使用多个图像帧和时间信息[73]，[74]学习基于视频的Re-ID[7]的视频表示。我们还审查了§2.1.5中Re-ID人员的若干特定架构设计

注意事项。文献中已经广泛研究了注意力方案来增强表征学习[85]。1） 第一组：关注人物形象。典型的策略包括像素级关注[86]和信道方向特征响应重新加权[86]、[87]、[88]、[89]或背景抑制[22]。空间信息集成在[90]中。2） 第2组：关注多人图像。[91]中提出了一种上下文感知注意特征学习方法，结合了序列内和序列间注意，用于成对特征对齐和细化。[92]，[93]中增加了注意力一致性属性。群体相似性[94]，[95]是另一种利用跨图像注意力的流行方法，涉及多个图像用于局部和全局相似性建模。第一组主要增强对未对准/不完美检测的鲁棒性，第二组通过挖掘多个图像之间的关系来改进特征学习。

**<font color='red'>基于全局的表征学习</font>**

全局特征表示学习为每个人图像提取全局特征向量，如图所示。2（a）。

<font color='red'>由于深度神经网络最初应用于图像分类[79]，[80]</font>，因此在早期将高级深度学习技术集成到人Re-ID领域时，全局特征学习是首要选择。

为了在全局特征学习中捕获细粒度线索，[81]中开发了一个由单图像表示（SIR）和交叉图像表示（CIR）组成的联合学习框架，使用特定子网络对其进行了三重丢失训练。广泛使用的ID区分嵌入（IDE）模型[55]通过将每个身份视为不同的类，将训练过程构造为多类分类问题。它现在广泛用于Re-ID社区[42]，[58]，[77]，[82]，[83]。Qian等人[84]开发了一个多尺度深度表征学习模型，以在不同尺度上捕捉辨别线索。

**注意事项。**文献中已经广泛研究了注意力方案来增强表征学习[85]。1） 第一组：关注人物形象。典型的策略包括像素级关注[86]和信道方向特征响应重新加权[86]、[87]、[88]、[89]或背景抑制[22]。空间信息集成在[90]中。2） 第2组：关注多人图像。[91]中提出了一种上下文感知注意特征学习方法，结合了序列内和序列间注意，用于成对特征对齐和细化。[92]，[93]中增加了注意力一致性属性。群体相似性[94]，[95]是另一种利用跨图像注意力的流行方法，涉及多个图像用于局部和全局相似性建模。第一组主要增强对未对准/不完美检测的鲁棒性，第二组通过挖掘多个图像之间的关系来改进特征学习

**<font color='red'>基于局部的表征学习</font>**



**（行人局部特征）外文综述**

在这项工作中，我们从另一个角度对研究方法进行了分类。我们对主流的研究方法进行了全面的回顾，并根据所研究特征的规模将其从粗到细分为三类：（1）基于全局的方法；（2） 基于零件的方法；（3） 基于多粒度的方法。这里，“粗略到精细”是指特征学习的规模，即上述三种分类。

同样，论文[18]中也提到了“从粗到细”的概念。在论文[18]中，“从粗到细”是指全局特征学习和局部特征学习的结合，在我们的论文中，这被分类为基于多粒度的人Re-ID方法。

此外，我们还根据流行的研究工具对每个分类进行了进一步划分。对于基于全局的方法，我们进一步将其分为三个分支：注意力驱动方法、图像生成方法和属性挖掘方法。

（1）基于全局的方法，其基于整个图像来获得辨别特征；

（2） 基于部分的方法，其关注图像区域以提取详细信息；

**<font color='red'>基于全局的表征学习</font>**

通常，基于全局的人Re-ID方法倾向于从整个图像中学习特征以获得特征向量，并使用该向量来检索图库图像[93，134]。初始卷积神经网络通常基于整个图像提取特征，因此基于全局的人Re-ID方法通常不需要太复杂的网络结构。基于全局的方法通常适用于具有突出前景和简单背景的场景，但对于具有严重遮挡或复杂环境等的场景则较差。在本节中，我们介绍了基于全局的人Re-ID的注意力驱动方法、图像生成方法和属性挖掘方法。本节介绍的注意力驱动方法适用于整个图像。

**<font color='red'>基于局部的表征学习</font>**

基于部分的人物Re-ID方法侧重于局部图像，以提取细粒度和区分性特征。这些方法在部分或闭塞的人Re-ID任务中表现良好，但可能忽略一些全局辨别信息。在本节中，我们将介绍三种广泛用于基于部分的人Re-ID的方法：图像分割方法、基于特征描述符的方法和注意力驱动方法。与上一节不同，本节介绍的注意力驱动方法适用于局部图像。

**(王素玉)行人重识别综述**

**<font color='red'>全局</font>**

全局特征表示学习为每个行人图像提取一个全局的特征表示，如图1所示．由于早期的研究都是将行人重识别看作图像分类问题，因此，早期的方法大多都使用全局特征表示学习方法．

文献［12］提出了一个判别性身份嵌入方法，将行人重识别视为一个多分类问题，每个行人作为一个单独的类别．文献［13］提出了一种同时学习全局特征和相似性度量的方法，计算一对图像的相似度．为了在全局特征学习中提取细粒度特征进行学习，文献［15］使用小型卷积核进行特征提取，提取行人图像中细粒度的特征．文献［16］提出了一种多尺度深度特征表示学习模型．该模型能够学习不同尺度下的全局特征表示，并自适应地进行匹配．文献［17］设计了一个轻量级网络进行全尺度特征学习，使用深度可分离卷积减少网络的参数量［18-20］，加速网络训练．

**<font color='red'>局部</font>**

在真实场景中，摄像头拍摄的行人图像存在遮挡、角度变化、背景变化等问题，见图2．因此，这些噪声区域会对全局特征造成极大的干扰．同时，由于行人姿态变化，在多个摄像头下检测到的图像帧姿态不一致的问题也会使全局特征无法匹配．目前，主流的趋势都是将全局特征与局部特征相结合使用以期实现更好的效果

通过人体姿态估计或粗略水平分割方法划分行人身体部位，然后从行人图像中该区域或人体部件提取局部特征，再与行人全局特征相融合，对遮挡、姿态变化具有鲁棒性［21］．

对于局部特征表示学习方法的研究，图像划分方式主要分为2类:水平分割［21-22］和姿态估计［23］．

文献［21］提出了基于部件的卷积基线(partbasedconvolutionalbaseline，PCB)模型．该模型采用统一的分割策略，将所有行人图像固定平均分割为6个部分并提取局部特征．同时，为了解决不同图像同一图像块不能良好对齐的问题，设计了精细局部池化(refinedpartpooling，ＲPP)模块进行对齐，增强了块内的一致性，进一步提高了性能．

文献［23］提出了一个姿态驱动的深度卷积(pose-drivendeepconvolution，PDC)模型，通过采用人体姿态估计的方法进行图像分割以解决行人姿态变化的问题．首先，对行人图像的14个关键点进行检测并定位，再基于关键点信息进行局部特征提取;然后，用仿射变换使得相同的关键点对齐．人体姿态估计方法提供了良好的局部特征，但是行人重识别任务的数据集和人体姿态估计任务的数据集存在较大差异．因此，使用人体姿态估计数据集训练的姿态检测器进行关键点检测时，很容易出现错检，产生噪声数据，对识别结果存在很大影响．虽然水平分割方法实现灵活，但是当遮挡区域较大或背景噪声较大时，效果并不理想．



**<font color='red'>注意力机制</font>**

近年来，注意力机制因为其良好的效果被广泛用于增强特征表示学习．文献［45］提出了和谐注意力卷积神经网络(harmoniousattentionCNN，HACNN)，联合学习“软”像素注意力和“硬”区域注意力，并用于学习全局特征和局部特征，最后将二者相结合，提高了识别的准确率．软注意力机制可以通过通道注意力、空间域注意力和混合域模型(将空间域和通道注意力混合)3种方式实现．

压缩和激励网络(squeeze-and-excitationnetworks，SENet)［46］是一种典型的通道注意力网络．针对行人重识别问题，文献［47］设计了一个完全注意力模块．完全注意力模块解决了SENet会丢失空间结构特征信息的问题，并且与SENet一样，可以用于不同的骨干网络，提高识别能力．文献［48］提出了一种属性注意力网络(attributeattentionnetwork，AANet)．如图5所示，AANet重点关注行人局部区域的人体属性信息，将人体属性与行人全局特征相结合，得到行人属性注意力．

为了更好地利用全局结构信息，文献［49］提出了一个有效关系感知全局注意力(relation-awareglobalattention，ＲGA)模块，可以使网络提取更具判别性的特征信息．文献［50］提出了一种混合高阶注意力网络(mixedhigh-orderattentionnetwork，图6在行人重识别中3种广泛使用的损失函数Fig．6ThreekindsofwidelyusedlossfunctionsinthepersonＲeIDMHN)．空间域和通道注意力是一阶注意力，提取的特征信息较为粗糙，高阶注意力可以提取特征图之间细微的差别，提高模型提取高阶表征的能力，从而提高识别准确率．同样，该模块可以与任何行人重识别网络结合使用．

在行人重识别任务中，注意力机制使模型倾向于关注更高相关性、冗余的细节特征信息，而忽略了低相关性的特征，导致模型不够鲁棒．为了解决这个问题，文献［51］提出了一种多样性正则化/频谱值差分正交正则化机制，包括特征空间正交正则化和权重正交正则化两部分．特征空间正交正则化有助于减少直接学习到的特征的相关度．权重正交正则化能够增加滤波器的多样性以增强学习能力和泛化能力．

#### 度量学习

**（程云舟）特征融合和度量学习**

(3)基于度量学习。在基于度量学习的行人重识别方法中，通常使用特征向量之间的距离来衡量样本对的相似度，距离越小，表明相似度越高，反之，则相似度越低（无特别说明，本文均采用欧式距离）。深度学习技术盛行以前，学者们就已经对度量学习进行了大量的研究，例如学习马氏距离函数[16]和投影矩阵[17]。近些年，对度量学习的研究主要集中在对损失函数的设计上，以此来监督深度神经网络特征学习的过程。虽然损失函数的表现形式有很多，但它们的最终目的都是一致的，使得在欧式空间中，属于同一类别的行特征向量彼此靠近，属于不同类别的行人特征向量互相远离。行人重识别领域中最常用的损失函数有身份损失、对比损失[18]、三元组损失[19]和四元组损失[20]等，损失函数的具体表达式我们将在第2章进行详细的介绍。

**身份损失：**在度量学习出现以前，学者们普遍使用身份损失在训练过程中提供监督信息，在度量学习的一系列损失函数提出后，学者们联合身份损失和度量学习的损失函数共同提供监督信息。

**对比损失：**在使用对比损失进行训练时，通常需要选择两张图片作为模型的输入。其中，每一对训练样本都有一个标签y来表示它们是否属于同一类别，y=1表示两张图片属于同一身份的行人图像，反之y=0的表示不属于。

**三元组损失：**三元组损失是行人重识别中最常用的损失函数，因其可以同时优化类内和类间距离。基于三元组损失训练的网络模型，其输入是三张图片为一组的样本集合，其公式定义如下：

**四元组损失：**四元组损失的提出是为了解决三元组损失的缺点，因为三元组损失在计算损失的时候仅考虑到正负样本与锚点样本之间的相对距离，而没有考虑到绝对距离。在三元组损失的基础上，四元组损失在采样阶段增加了一张不同身份的负样本图片，来同时优化正负样本间的相对距离和绝对距离。

**（王素玉）行人重识别综述**

度量学习旨在使用一个通过从数据中学习获得的最优距离度量方程，度量样本之间的相似性［52］．深度度量学习是度量学习的一种方法，目标是学习一个从原始特征到嵌入空间的映射，使同类别对象在嵌入空间中的距离较近，不同类别之间的距离较远．距离计算方程一般使用欧氏距离和余弦距离．在基于深度学习方法的行人重识别任务中，损失函数代替了传统度量学习的作用来指导特征表示学习．在行人重识别任务中广泛使用的损失函数主要分为:实例损失、验证损失和三元组损失．同时，近年提出的在线匹配实例损失和圆损失也取得不错的效果．

实例损失是将行人重识别任务当作一个图像分类问题［12］，把每个行人当作一个单独的类别．测试时，对于输入图像xi和标签yi，预测概率p(yi|xi)通过SoftMax函数归一化编码，然后使用交叉熵函数计算实例损失．

三元组损失将行人重识别模型的训练过程视为一个检索排序问题．三元组损失的基本思想是:正样本对之间的特征距离与负样本对之间的特征距离的差小于预先定义的阈值［55］．通常一个三元组损失包括一个锚点样本xa，一个来自同一个类别的正样本xp和一个来自其他类别的负样本xn．样本之间的距离d使用欧氏距离函数计算．





### 跨模态行人重识别

#### 引言

**（师姐）开题报告**

基于可见光——红外图像跨模态行人重识别问题于2017在ICCV会议上被正式提出[4]，是近几年新兴的研究方向。解决VI-ReID的关键在于 减小模态内的差异和模态间的差异。根据解决方式的不同，可以分成以下两种方法：模态共享特征学习和模态特定信息补偿。



**（西安电子科技大学）跨模态外文综述**

最近，已经提出了许多VI ReID模型来解决VI ReID中的跨模态变化和模态内变化。在本节中，我们将对现有模型进行全面和详细的审查（如图1所示）。图4显示了现有VI ReID模型的一般程序。输入的可见图像或红外图像首先通过使用一些数据增强策略来增强（在训练策略中），然后被馈送到ReID网络以提取相应的人物特征。最后，匹配来自不同图像的人物特征。应该注意的是，在本文中，我们将从单模态图像中提取的特征称为单模态特征，可以进一步将其分为模态特定特征和模态共享特征。其中，特定于模态的特征是单模态图像所特有的，例如可见图像中的颜色。

而模态共享特征是可见图像和红外图像中共同存在的特征。

#### 模态共享特征学习

**（西安电子科技大学）跨模态外文综述**

基于模态共享特征学习的模型旨在为VI ReID提取那些有区别的模态共享特征。此外，根据它们提取模态共享特征的方法，如图1所示，我们将这些现有的基于模态共享特征学习的模型进一步分类为三种类型，即特征投影、特征解缠和度量学习。

具体而言，如图5（a）所示，**基于特征投影的模型**旨在首先将这些单模态特征投影到共享特征空间中，以解决跨模态变化。然后，他们在该特征空间中提取区分模态共享特征，以处理模态内变化。

如图5（b）所示，**基于特征解缠的模型**旨在首先设计ReID网络，该网络可以明确和直接地将单一模态特征解缠为模态特定特征和模态共享特征。然后，他们使用VI ReID的模态共享特征。

不同的是，**基于度量学习的模型**不侧重于优化网络结构，而是强调使用不同的损失函数或训练策略来优化学习过程，以便于为VI ReID提取更多与人相关的和模态共享的特征。在以下内容中，我们将详细介绍三种基于模态共享特征学习的模型。

<font color='red'>**特征投影**</font>

作为VI ReID领域的开拓性工作之一，Wu等人[11]提出了第一个基于特征投影的模型。如图6所示，他们探索了将不同模态的特征投影到共享特征空间中以提取其模态共享特征的方法。为此，他们提出了三种类型的网络结构，即单流结构、双流结构和非对称全连接（FC）层结构。这些结构通常使用一些参数共享卷积层来同时将这些单模态特征投影到共享特征空间中并提取模态共享特征。例如，如图6所示，一个流结构共享RGB和IR图像的整个网络，以从两个模态中提取模态共享特征。双流结构首先使用两个独立的网络分别从输入RGB和IR图像中提取单模态特征，然后使用参数共享网络将提取的RGB和IR特征投影到VI ReID的共享特征空间中。非对称FC层结构共享除最后一个FC层之外的几乎所有参数，其目的是在特征提取过程中实现特征投影，并通过不同FC层提取区分特征。这些结构已经成为最广泛使用的基础结构，参数共享网络的设计已经成为大多数后续基于特征投影的模型的核心，因为它直接影响这些模态共享特征的提取。

因此，这些后续工作（如表2所示）关注参数共享网络的优化，以更好地提取那些辨别模态共享特征。根据他们的方法，我们将现有的基于特征投影的模型进一步划分为6个子类，即分别探索多层次特征、挖掘全局和局部信息、使用注意力机制、使用图卷积网络、优化批处理归一化层和优化分类器。我们将在以下内容中详细介绍这些子类。

​	**<font color='red'>多尺度</font>**

探索多级特征：一般来说，低级特征主要包含详细信息，高级特征主要包含语义信息。因此，这两种类型的特征是互补的。考虑到这一点，一些工作试图利用共享特征空间中的多层次互补信息来提取更具鉴别性的模态共享特征。例如，在[17]中，将多粒度网络（MGN）集成到双路径框架中，以组合多级特征并进一步提取区分模态共享特征。Cheng等人[15]提出了一种双流多层对应融合网络（DMCF）。DMCF首先通过参数共享特征提取器分别从RGB和IR图像中提取不同级别的单模态特征。然后，它采用参数共享的多分支结构来融合来自两种模态的相同级别的特征，并使用不同的多粒度划分方法来增强模态共享特征。Liu等人[16]提出在他们的共享网络中使用一些跳过连接来探索中层特征，以提高学习模态共享特征的可分辨性。

​	**<font color='red'>挖掘全局和局部信息</font>**：挖掘全局和本地信息可以使VI-ReID模型抗失准。

因此，许多研究人员致力于如何通过专用参数共享网络来有效地挖掘共享特征空间中的两种类型的信息。具体而言，一些工作侧重于提取有区别的零件特征。例如，Liu等人[22]首先从输入图像中提取模态共享特征，然后利用统一的分割策略来获得更具鉴别性的模态共享人部分特征。Wei等人[21]在他们的参数共享网络中提出了自适应身体分割（ABP）模块，以自动检测和区分有效的部分表示。

类似地，Wei等人[23]提出了一种基于柔性身体分割（FBP）模型的对抗性学习方法（FBP-al），该方法还可以根据行人图像的特征图自动区分部分表示。Park等人[28]提出在训练期间利用交叉模态图像之间的密集对应，以提取一些有区别的像素级局部特征。

不同的是，其他工作研究了联合开发VI-ReID全球和本地信息的方法。例如，Chen等人[27]将局部特征与全局特征相结合，以获得最终的模态共享特征。Zhang等人[20]提出了一种新的多尺度部分感知级联框架（MSPAC），以级联方式从局部到全局聚合多尺度细粒度特征，这导致了包含丰富和增强的语义特征的统一表示。Liu等人[24]在其参数共享网络中提出了一种双粒度三重丢失模块，其中提取的模态共享特征可以从精细（局部）到粗粒度（全局）的方式导出，因此更具鉴别性。



​	**<font color='red'>使用注意机制：</font>**在VI-ReID模型中，注意机制主要用于参数共享网络，以从那些与人相关的区域中提取辨别模态共享特征。具体而言，Wu等人[37]提出了一种新的联合模态和模式对齐网络（MPANet），该网络使用基于注意力机制的模式对齐模块来发现VI ReID的行人不同模式中的跨模态细微差别，从而提取更具区别性的特征。受自我注意机制[51]的启发，Wu等人[34]提出了一种位置注意力引导学习模块（PALM），以捕获不同人位置之间的长距离依赖性，以增强局部特征的可分辨性。

类似地，Cheng等人[31]提出了一种双路径深度监控网络（DDSN），该网络还使用了自我关注机制[51]来捕获输入图像的人物区域内的潜在上下文信息。Li等人[30]引入了空间注意力模块和通道注意力模块，以分别探索空间和通道维度中的视觉特征依赖性。Jiang等人[29]提出了一个“蝴蝶”注意模块，以便于提取模态之间的共同局部特征，并将其与全局特征进一步融合以进行匹配。此外，注意机制也可用于减少情态差异。例如，Wei等人[32]提出了一种共同关注机制，通过学习和协作模态共享特征来弥合两种模态之间的差距，从而显著减少模态差异。

**<font color='red'>度量学习</font>**

​	**<font color='red'>身份丢失：</font>**身份丢失可以促进VI ReID网络中与人相关的信息提取，这通常通过使用原始交叉熵损失进行训练来实现。不同的是，一些工作试图优化身份丢失，以提取更具歧视性的与人相关的特征。例如，Hao等人[59]使用Sphere Softmax函数来学习超球面流形嵌入，并约束该超球面上的模态内变化和跨模态变化，从而可以用清晰的边界对不同身份的图像进行分类。



​	**<font color='red'>对比损失及其变体：</font>**为了减少跨模态变体，一些作品在VI ReID中引入了对比损失。例如，Ye等人[57]提出了一种分层跨模态度量学习策略，以更好地利用VI ReID中的对比损失，这首先将两种不同模态转换为一致的空间。之后，随后学习模态共享特征，同时在一致空间中压缩来自同一个人的特征。[79]提出了一种多层约束（MLC）损失，其本质上应用了跨模态对比损失来约束多层特征。



​	**<font color='red'>三重态丢失及其变化：</font>**Ye等人[58]首先将VV-ReID任务中的三重态损失转移到VI ReID任务中。具体而言，他们提出了双向双约束顶级（BDTR）损失，其中包含两个三元组约束，即跨模态顶级约束和模态内顶级约束，以分别解决跨模态变化和模态内变化。基于BDTR损失，Liu等人[82]提出了一种双向三约束顶推排名损失（BTTR），它引入了额外的三元组损失，即模态间顶推排名丢失，以进一步促进学习区分性特征嵌入。根据BTTR损失的相同想法，Wang等人[65]还提出了混合模态三重态损失。Zhao等人[66]提出了一种硬五倍体丢失，其目的是从最硬的五倍体对中选择最硬的全局三倍体和最硬的跨模态三倍体，以同时处理跨模态和跨模态变化。Zhang等人[80]提出了一种综合的混合模态度量学习框架，该框架还涉及四种基于配对的相似性约束，以解决所有模态内和跨模态变化。

不同的是，一些工作试图优化这些三重态损耗变体中的距离函数。例如，等人[67]和Ye等人[64]提出用余弦距离代替BDTR损失的欧几里德距离进行训练。Hu等人[78]将三重态损失与软边缘损失相结合，从而获得了VI ReID的新的最大类内三重态（MICT）损失。此外，Wang等人[69]提出了一种硬模态对齐（HMA）损失，该损失首先挖掘具有大模态差异的硬特征子空间，然后在该硬特征子中执行一些三元组约束，以使模态分布更易于区分。基于圆损失[86]，Liu[85]提出了一种用于VI ReID的新的记忆增强单向度量学习方法。它学习了两个单向的显式跨模态度量，并通过基于记忆的增强进一步增强了它们。



​	**<font color='red'>中心损失及其变化：</font>**中心损失旨在探索不同特征中心之间的距离关系，而不是直接约束特征距离。具体而言，Zhu等人[75]首先提出了异质中心损失（HC损失），通过约束两种异质模态之间的类内中心距离来学习模态共享特征。Liu等人[77]进一步提出，通过提出新的PSE损失，将异质中心损失与三重态损失结合起来。

通过用中心距离替换相应的特征距离，这种损失放松了传统三元组损失的严格限制。Li等人[83]将PSE损失改写为批处理所有形式，即使用批处理中的所有样本，以提高模型性能。Ling等人[71]提出了一种中心引导的度量学习（CML）约束，该约束在全局上减少了同一类的模态间中心之间的距离，并鼓励不同类的中心远离以处理大的跨模态差异。同样，它将每个样本拉到其对应模态的类中心附近，以克服模态内的变化。Ye等人[61]提出了一种双向中心约束顶级（eBDTR）损失，该损失将前两个约束（即，跨模态顶级约束和跨模态顶级限制）合并到单个公式中，以处理跨模态和内部模态变化。Sun等人[76]提出了一种新的整体-个体训练（WIT）模型，该模型包含整体部分和个体部分。在该模型中，为整个部分开发了两个损失函数，即中心最大均值差异（CMMD）损失，以拉入两种模态的中心，以及类内异质中心（ICHC）损失，将具有相同身份的图像拉入其跨模态中心。同时，对于单个部分，使用交叉模态三元组（CMT）损失来区分具有不同身份的行人图像。



**（Discover nusiance）**



**为了解决模态差异带来的挑战，已经提出了许多跨模态人重新识别方法**。Wu等人[33]在公共空间中提出了深度零填充网络学习特征，并构建了第一个名为SYSUMM01的大规模可见红外数据集。为了约束模态内和模态间的变化，[5]中提出了端到端双流超球面流形嵌入模型。在[35]中，引入了具有双向双约束顶层损失的双路径网络来学习模态对齐特征表示。Ye等人在[34]中还提出了一种分层的跨模态匹配模型，该模型联合优化了模态特定和模态共享度量。DFE[4]被提议在区域和模态上对齐信息。一些工作是基于GAN的方法，cmGAN[1]、D2RL[29]、AlignGAN[25]和JSIA ReID[26]。cmGAN采用生成对抗训练将特征映射到公共空间。D2RL应用GAN来生成缺失的模态信息，将特征提取器的输入扩展到四维。此外，AlignGAN和JSIA ReID在统一的GAN框架中实现了像素和特征双层对齐。类似地，Li等人[12]和cm SSFT[14]在这两种模态之间生成了一种新模态，以缓解模态差异。然而，这些方法建议补充模态信息或将特征直接映射到公共特征空间。

他们主要专注于缓解模态差异，而忽略了细微差别的影响，这不可避免地限制了性能的提升。



**注意机制。**人类视觉系统有一个重要的特性，即人类有选择地关注一系列一瞥中的重要部分，以捕捉有价值的信息。关于人类视觉系统，已经有几次尝试采用注意力机制来提高神经网络的性能。Hu等人引入SENet[7]来开发维度关系。他们提出了挤压和激发模块，以将注意力机制应用于具有全局平均集合特征的维度。考虑到任意两个位置之间的关系，[28]提出了非局部神经网络来捕捉它们之间的关系。为了拓宽视野，即让它同时看到“什么”和“在哪里”，CBAM[31]被提出，它利用了空间和维度方面的注意力。根据这些方法，我们提出了模态缓解模块（MAM），以通过对通道的关注来保护身份，同时缓解模态差异。我们提出了模式对齐模块（PAM）来发现不同模式中的细微差别。



**师生模型。**在半监督学习方法和知识提炼方法中，师生模型扮演着重要的角色。师生模型的关键思想是通过收集不同模型的预测，为每个样本创建一致的培训监督。时间集合[11]以指数移动的方式保存了每个样本的平均预测，作为未标记样本的监督。为了降低保存预测的成本，Mean Teacher[23]在不同的训练迭代中临时平均模型权重，以创建未标记样本的监督。与教师和学生之间的单向转移不同，深度相互学习[38]是一个学生的集合，他们在整个培训过程中协作学习并相互教授。MMT[2]将相互学习和均值教学相结合，旨在通过使用两个均值教师为另外两个网络生成软标签来减少伪标签噪声的影响。受这些方法的启发，我们制作了两个模态特定分类器来预测这两个模态的特征。以这种方式，通过使两个分类器具有模态特定知识但预测相同结果，引导网络在此过程中提取模态无关特征。





**（Structural Position）**

第一类[29]–[33]试图通过补偿从一种模态到另一种模态缺失的特定线索来减少模态差异。他们应用生成性对抗网络[34]来对齐两种模式的图像风格。Wang等人[31]设计了一个对齐生成对抗网络，以实现VI ReID任务两种模式之间的像素级和特征级对齐。为了减轻模态内和跨模态差异，分层跨模态解纠缠[30]方法通过图像生成网络将图像信息分解为ID辨别（例如，体型、服装风格）因素和ID排除（例如，照明、姿势）因素。由于从红外模态转换为可见模态的图像的颜色是任意的，因此这些方法很难选择VI ReID的目标。

第二类侧重于通过网络设计[11]、[12]、[27]、[35]、[36]或损失函数优化[13]、[15]、[17]来挖掘可共享的跨模态特征表示。Wu等人[11]提出了一种具有零填充策略的单路径网络，以解决跨模态ReID问题。Chen等人[36]基于神经架构搜索自动执行跨模态特征选择过程。Huang等人[27]设计了一个多级模态共享特征提取网络，以学习模态共享外观表示和模态变量关系表示。Ye等人[15]使用增强灰度模态来形成三模态度量学习框架，以消除模态变化。由于全局级特征学习，上述方法对背景噪声和模态差异的鲁棒性有限。最近，类似于单模态ReID[6]，[37]，[38]，一些VI ReID方法[16]，[17]，[35]提出探索部分级特征表示，以解决VI ReID中的不对齐问题。Wei等人[17]设计了一个基于柔性身体分割模型的对抗性学习框架，以探索不同模式之间的详细信息。在[35]中，针对VI ReID提出了模态内部分级特征聚合和跨模态图学习[6]、[39]、[40]，有效地选择了用于跨模态匹配的辨别模态表示。



#### 模态特定信息补偿

（西安）

如表5所示，已经提出了许多基于模态特定信息补偿的模型，其遵循这样的思想，即首先从现有模态特定信息中生成缺失的模态特定信息以解决跨模态变化，然后从生成的原始信息中提取有区别的人特征以处理模态内变化。根据它们生成缺失模态特定信息的方式，我们将这些模型进一步划分为两个子类，即单模态信息补偿和跨模态信息补偿。具体而言，如图7（b）所示，基于单模态信息补偿的模型通常生成一个缺失的模态特定信息，而不是所有信息。如图7（c）所示，基于跨模态信息补偿的模型同时生成VI ReID的所有缺失模态特定信息。

一些作品从真实的可见光图像中生成假红外图像进行补偿。例如，Wang等人[88]提出了第一个基于单模态信息补偿的工作，即对齐生成对抗网络（AlignGAN），该网络采用了两种对齐策略，包括像素级对齐和特征级对齐，用于VI ReID。具体而言，AlignGAN首先通过从真实可见图像生成假红外图像来实现像素级对准，然后通过特征对准模块匹配生成的假红外图像和真实红外图像。之后，Zhang等人[89]提出了一种师生GAN模型（TS-GAN），该模型从现有可见图像中生成假IR图像，以减少跨模态变化，并指导有区别的人特征的提取。

不同的是，一些作品采用了从真实红外图像生成假可见图像的方式进行补偿。例如，Dai等人[92]设计了一个名为CE2L的新模型，该模型首先通过图像模态转换模块将红外图像转换为可见图像，然后通过使用特征提取模块和VI ReID的特征学习模块学习其辨别特征。Zhong等人[87，90]建议使用彩色化方法为灰度图像着色，而不是使用跨模态转换模型。因此，他们提出了一种灰度增强彩色化网络（GECNet），该网络首先将从原始红外图像中提取的特征与其彩色图像中的特征进行融合，然后将融合的特征与从可视图像提取的特征进行匹配，以用于VI ReID。

大多数现有的基于跨模态信息补偿的模型通过从现有模态生成缺失模态的图像来补偿缺失的模态特定信息，即图像级补偿。例如，Wang等人[91]提出了一种双水平差异减少学习（D2RL）策略。该策略首先通过设计图像级子网络将红外图像转换为可见图像，将可见图像转换为红外图像，从而减少了模态差异。然后，提出了一个特征级子网络，通过引入一些特征级约束来减少剩余的外观差异。类似地，Fan等人[94]设计了一种模态转移生成对抗网络（mtGAN），以从目标模态中的源图像生成跨模态对应物，从而获得同一个人的成对图像。Wang等人[93]提出生成跨模态配对图像，并执行全局集合级和细粒度实例级对齐。

之后，Yang等人[95]提出了[93]的扩展版本。

具体来说，在双层策略的基础上，他们进一步引入了一个潜在的流形空间，以随机抽样和生成一些不可见类的图像，从而在测试时实现更好的泛化。Hu等人[96]提出了一种新的对抗性解纠缠和相关网络（ADCNet），该网络进一步投资于在跨模态图像翻译处理中学习人的模态不变和辨别表示，从而获得更好的结果。Xia等人[97]提出了一种图像模态转换（IMT）网络，该网络学习从源模态的图像生成目标模态的图像。具体来说，他们通过CycleGAN进行了跨模态图像转换。这些生成的图像用作数据增强工具，以扩大训练数据集的大小并增加其多样性。Liu等人[101]首先通过重新访问现有的基于模态特定特征补偿的模型，揭示了性能不足的原因，然后相应地提出了一种新的基于两阶段GAN的模型，实现了新的最先进性能。代替图像级补偿，Lu等人[100]根据不同模态样本的共享特征对其相似性进行建模，然后在模态之间/跨模态传输共享和特定特征，从而实现特征级补偿。

不同的是，Zhang[102]提出了一种新的特征级模态补偿网络（FMCNet），它不是生成缺失模态的图像，而是直接从另一模态的现有模态共享特征中生成一个模态的那些缺失模态特定特征。为此，首先设计了单模态特征分解模块，将单模态特征分为模态特定特征和模态共享特征。然后，提出了一个特征级模态补偿模块，以从现有模态共享特征中生成那些缺失的模态特定特征



（Structural position）

可见红外人ReID：随着深度学习的快速发展，各种计算机视觉任务[20]–[26]得到了广泛的研究。可见红外人员重新识别（VI ReID）[11]、[27]、[28]旨在实现夜间视频监控。给定一个人的可见/红外图像，VI ReID系统从红外/可见图库集合中找到相应的图像。此外，现有的VI ReID方法可大致分为两大类。



## 评述

### 思路

通过阅读大量的文献，你发现现有方法有哪些不足？讲出来。你会对现有方法做出哪方面的改进？



### 材料

**（师姐，开题报告）**

目前所提出的方法大多选择补充模态信息或直接将特征映射到共同特征空间，主要关注于缓解模态差异，而忽略细微差别的影响，这不利于模型学习到具有辨别性的身份特征。对于可见光图像，服装信息是区分不同身份的重要线索，可见光图像的特征容易与服装信息过拟合，不利于模态对齐。采用生成对抗网络方法生成的图像极大地增加了计算量，增加了跨模态学习的不确定性，限制了实际模型部署的适用性。因此本课题的研究将重点放在全局特征和局部特征的共同学习以及与衣服信息无关的特征学习两个方面，使得模型不仅能够学习到两种模态的共同特征，还能学习到具有辨别性的身份特征。



**(西安电子科技大学，英文综述)**

Although great progress has been made, there are still some limitations on existing modality-shared feature learning based models. Specifically, **existing models only focus on extracting more discriminative modality-shared appearance features for VI-ReID, which have also been proven to be effective in VV-ReID**. However, in VI-ReID, the modality-shared appearance features co-existing in RGB and IR images are relatively fewer. As a result, only using modality-shared appearance features for VI-ReID may not work well as in VV-ReID and may have an upper bound. **Therefore, on top of modality-shared appearance features, exploring more types of modality-shared features is essential for future works.** For example, some structure information of pedestrians, e.g., the connections/relations among key points of the human body, is naturally identity-related and modality-invariant, which can complement those modality-shared appearance features for identifying persons with similar appearances but different structures. Although Chen et al [36] have made the first step, how to extract those modality-invariant relations/structures via some existing tools, such as graph convolutional networks [121,122] or Transformers [123,124], is still an important direction for future works.

尽管已经取得了很大的进展，但现有的基于模态共享特征学习的模型仍然存在一些局限性。具体而言，现有模型只专注于为VI ReID提取更具辨别力的模态共享外观特征，这也已被证明在VV ReID中有效。然而，在VI ReID中，RGB和IR图像中共存的模态共享外观特征相对较少。因此，仅使用VI ReID的模态共享外观特征可能无法像VV ReID那样工作，并且可能有上限。因此，在模态共享外观特征之上，探索更多类型的模态共享特征对于未来的工作至关重要。例如，行人的一些结构信息，例如，人体关键点之间的连接/关系，自然是身份相关的和模态不变的，这可以补充用于识别具有相似外观但不同结构的人的那些模态共享外观特征。尽管Chen等人[36]已经迈出了第一步，但如何通过一些现有工具（如图卷积网络[121122]或变压器[123124]）提取这些模态不变关系/结构仍是未来工作的重要方向。



除了每种类型模型的潜在研究方向外，该领域还存在一些需要关注的一般问题：

（1）数据集：只有两个VI ReID数据集用于VI ReID模型的训练。此外，这两个数据集都相对较小，这将阻碍大多数基于深度学习的VI ReID模型的开发。因此，需要更多更大的VI ReID数据集。研究人员迫切需要建立一些新的大规模数据集，以推动VI ReID领域的发展。

（2） 轻量级VI ReID模型：在现实应用中，画廊的规模很大，并且不断增加。这要求VI ReID模型应足够快，以便实时处理大规模数据。然而，与VV-ReID相比，VI-ReID模型通常包含更多的参数来处理来自两种不同模态的信息。因此，开发轻量级VI ReID模型对于VI ReID的实际应用也很重要。

（3） 半监督和非监督VI ReID：一般来说，训练基于深度卷积神经网络的VI ReID模型需要大量带有标签的训练样本。然而，为VI ReID手动注释如此数量的跨模态样本比为VV ReID注释那些单模态样本要昂贵得多。基于半监督学习或基于无监督学习的VI ReID模型可以有效地解决这些问题。Liang等人[125]已经首次尝试对基于无监督学习的VI ReID模型进行研究，并提出了第一个无监督RGB-IR跨模态重新识别（uRGB IR re-ID）模型。基于半监督学习或基于无监督学习的VI ReID的研究仍然是一个具有挑战性的问题。



**（武汉大学，外文综述）**

从表2和表3中，我们观察到，近年来，VI-ReID在两个公共数据集上的性能有了很大改善。同时，**网络架构的复杂性也增加了。在现有的网络架构中，特征学习和度量学习是必不可少的模块。特征学习的主要功能是提取模态特定和共享的特征。最近，一些旨在提取有效特征的工作变得更加流行，包括全局局部特征融合。**在这里，具有相同ID的两个特征之间的距离将被拉动，而具有不同ID的两种特征之间的间距将被距离度量学习推送。

根据实验结果，我们在VI ReID中观察到以下方向：

•单流网络架构。在测试基线方面，我们认为，与现有设置相比，具有更实用设置的新测试基线对研究更有价值。考虑到现有的双流网络架构不能有效地解决新设置的挑战，可以提取两种异构模态的更鲁棒和有效特征的单流网络可能是一种趋势。

•缺乏监督或自我监督。考虑到获得足够数量的高置信度数据的困难，我们应该专注于那些没有标签或低标签置信度的数据。在ReID中，利用此类数据解决相关问题的方法（如[85,86]中的方法）非常先进。我们相信，未来将在VI ReID中出现许多关于弱监督或自我监督数据的作品。

•转移学习。随着神经网络数量的增长，结构变得越来越复杂，我们期望神经网络在面临类似任务时能够利用当前的一些资源。ReID[87–**89]中广泛使用的迁移学习的进一步研究可能是VI ReID的一个重要方向。**



**（Discover Nuciense）**

可见红外人物重新识别（re-ID）旨在匹配来自不同模式的相同身份的行人图像。**现有的工作主要集中于通过对齐不同模态的特征分布来缓解模态差异。然而，诸如眼镜、鞋子和衣服长度等细微但有区别的信息尚未被充分发掘，尤其是在红外模式中。在没有发现细微差别的情况下，仅使用模态对齐来匹配不同模态的行人是具有挑战性的，这不可避免地降低了特征的显著性。**在本文中，我们提出了一种联合模态和模式对齐网络（MPANet）来发现可见红外人物Re-ID的不同模式中的跨模态细微差别，该网络引入了模态减轻模块和模式对齐模块来联合提取辨别特征。**具体地，我们首先提出了一种模态减轻模块，以从提取的特征图中去除模态信息。然后，我们设计了一个模式对齐模块，它为一个人的不同模式生成多个模式图，以发现细微差别。最后，我们引入了一种互均值学习方式来缓解模态差异，并提出了一种中心聚类损失来指导身份学习和细微差别发现。**在公共SYSU-MM01和RegDB数据集上的大量实验表明MPANet优于现有技术。



为了执行可见红外人物Re-ID，已经提出了几种方法[1，4，12，29，33]，这些方法旨在通过对齐特征或像素分布来缓解模态差异。尽管取得了令人鼓舞的成就，但由于红外图像中隐藏的未发现的有效信息，现有方法在学习不同模态的辨别特征方面仍然能力有限。在跨模态人Re-ID中，不同图像对的细微差别出现在不同的模式中，例如T恤和裤子的长度、鞋子的类型以及是否戴眼镜。如果没有很好地发现这些信息，红外特征的可分辨性将比可见特征差，如图1（c）所示。发现细微差别同时缓解模态差异在可见红外人Re-ID中起着重要作用。最近已经提出了相当多的细粒度的人重新识别方法[15，24，27，36，40，43]，它主要将身份分类、人辅助信息合并到一个框架中，以考虑人的细节。然而，这些方法需要额外的标记先验，例如属性、关键点和人类解析信息，寻找某些部分并平等对待这些部分，而不是自适应地选择它们。

由于缺乏必要的信息和模态的变化，这些方法无法在跨模态环境中学习辨别特征。因此，发现现有方法中未充分利用的细微差别自然可以提高特征的辨别能力



**（Structure Position）**

**然而，这些方法主要集中于利用外观信息进行跨模态学习，而忽略模态不变的结构信息，从而导致有限的模型性能。**语义级细粒度模态特征由两个方面的结构信息引导。一方面，我们提出了一种有人参与的结构表示（ASR），它提取与结构相关的外观特征，以减轻两种模态中背景噪声的影响。另一方面，为了提高部件级模态特征的可分辨性，我们设计了基于变换器的部件交互（TPI）模块，以挖掘复杂的位置结构关系，对遮挡和姿态变化具有更强的鲁棒性。



根据Gao等人[45]，我们通过关系网络对关键点热图进行编码，以表征每个模态中人体的结构特征。基于结构信息，我们进一步探索了**与结构相关的外观特征和零件级特征，以减少背景噪声和未对准对VI ReID的影响。**



在本文中，**为了减轻遮挡和姿态变化导致的失准的影响，**我们通过变换编码器执行部分级交互，以挖掘潜在的位置关系，并提高部分级模态表示的判别能力。据我们所知，这是第一次评估变压器在可见红外人员重新识别中的有效性的研究。

# 研究内容

## 拟解决的关键问题

**（师姐，开题报告）**

1、  可见光模态与红外模态内部的细微差别挖掘不够充分。可见光模态和红外模态内部的图像是两种异质的图像，有着很大的不同。在VI-ReID问题中，很多研究方法将注意力集中于提取两种模态所共有的信息，而忽略了细微差别。然而，只有将各个特定模态的特征都提取出来，然后将其进行融合，才能得到行人的具有辨别性的模态不变性特征，这对于VI-ReID任务来说是十分重要的。

2、  两种成像模态下获取的图像存在较大差异。红外图像相比可见光图像而言，缺失较多颜色信息和纹理信息。对于可见光图像，服装信息是区分不同身份的重要线索，可见光图像的特征容易与服装信息过拟合，不利于提取两种模态的共同特征。

3、  跨模态数据集数据量不足。与单模态行人重识别数据集相比，VI-ReID数据集的数据量较少。目前，标准的用于跨模态行人重识别领域的数据集的图像数量最多为三十多万张。因此，跨模态行人重识别的深度学习模型非常容易出现训练不充分的问题，从而对深度模型的精度产生负面的影响。





**（西安大学，外文综述）**

跨模态变化对VI ReID产生了不利影响。

首先，如图3（a）所示，它将导致RGB模态和IR模态之间的不同特征分布，这进一步导致同一身份的不同模态之间的若干未对准问题。例如，这将使同一身份内的跨模态差异大于不同身份内的模态差异。其次，如图3（b）所示，它使更多的人歧视信息受到干扰。例如，在VV ReID中，颜色信息是识别不同人物的最重要的外观线索之一。然而，在VIReID中，几乎不能使用颜色信息。这意味着VI ReID任务中的有用信息远远少于VV ReID任务，这使得VI ReID更具挑战性。与VV ReID类似，VI ReID中的模态内变化也由视角、姿势和曝光中的人物变化引起。这进一步增加了VI ReID的难度



（Discover Nusainse）

现有的工作主要集中于通过对齐不同模态的特征分布来缓解模态差异。然而，诸如眼镜、鞋子和衣服长度等细微但有区别的信息尚未被充分发掘，尤其是在红外模式中。在没有发现细微差别的情况下，仅使用模态对齐来匹配不同模态的行人是具有挑战性的，这不可避免地降低了特征的显著性。



（Structure Position）

大多数先前的VI ReID研究[11]，[13]–[16]建议学习可共享的跨模态外观特征，以应对上述挑战。通常，这些方法首先使用两个相同的和非共享的权重网络来分别提取可见图像和红外图像的模态特定特征，以处理跨模态视觉差异。然后，采用共享网络学习模态共享特征并进行跨模态相似性优化。

尽管这些方法可以提取某些模态共享特征并提高模型的性能，但它们对失调和背景噪声的鲁棒性是有限的，因为它们只从图像级信息中学习粗略的共享特征。为了减少样本噪声的影响，一些工作[16]，[17]对VI ReID执行部分级特征学习，为每个模态捕获细粒度局部信息。然而，这些方法将人物图像统一地划分为多个区域，用于区域级局部特征拼接，这对遮挡和姿态变化很敏感。更糟糕的是，他们独立学习部件级表示，而不考虑不同局部部件之间的潜在交互，这无法自适应地挖掘关键区域。为了增强跨模态学习对背景噪声和失调的鲁棒性，我们首先从以下两个方面提出了我们的解决方案：



## 研究内容

**摘要**（出现什么问题，用了什么模块解决，我拿来改吧改吧）

**相关工作**（领域a有什么问题，提出了a1方法解决；领域b有什么问题，提出了b1方法解决）

**介绍**（编故事要吹得狠一点）

------

（师姐，开题报告）

1、  数据增广

如何将搜索空间减小的基于NAS方法的数据增广策略应用到可见光——红外图像跨模态行人重识别领域中，自动搜索适合数据集的最佳数据增广方法，来增强模型的鲁棒性。

2、  提取两种模态下各自具有辨别性和鲁棒性的特征

VI-ReID不仅两种模态图像之间存在巨大差异，模态内也有差异，需要设计一个网络结构来学习两种模态下各自具有辨别性和鲁棒性的特征。

3、  构建合适的度量函数

  度量函数可以将不同行人的特征映射到一个空间，使得不同类别样本之间的距离在该空间上较远，同类别样本之间的距离在该空间上较近。研究构建合适的度量函数，使得跨模态相同ID下的图像之间的距离小于跨模态不同ID下的图像之间的距离。



（网上视频）

![image-20221214151645758](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221214151645758.png)



（Discover Nuisance）

**摘要**

可见红外人物重新识别（re-ID）旨在匹配来自不同模式的相同身份的行人图像。现有的工作主要集中于通过对齐不同模态的特征分布来缓解模态差异。

然而，诸如眼镜、鞋子和衣服长度等细微但有区别的信息尚未被充分发掘，尤其是在红外模式中。在没有发现细微差别的情况下，仅使用模态对齐来匹配不同模态的行人是具有挑战性的，这不可避免地降低了特征的显著性。

在本文中，我们提出了一种联合模态和模式对齐网络（MPANet）来发现可见红外人物Re-ID的不同模式中的跨模态细微差别，该网络引入了模态减轻模块和模式对齐模块来联合提取辨别特征。具体地，我们首先提出了一种模态减轻模块，以从提取的特征图中去除模态信息。然后，我们设计了一个模式对齐模块，它为一个人的不同模式生成多个模式图，以发现细微差别。最后，我们引入了一种互均值学习方式来缓解模态差异，并提出了一种中心聚类损失来指导身份学习和细微差别发现。

在公共SYSU-MM01和RegDB数据集上的大量实验表明MPANet优于现有技术。



**相关工作**

可见红外线人Re-ID。近几年来，由于其在恶劣光照条件下的有效性，可见红外人识别系统受到了越来越多的关注。

为了解决模态差异带来的挑战，已经提出了许多跨模态人重新识别方法。Wu等人[33]在公共空间中提出了深度零填充网络学习特征，并构建了第一个名为SYSUMM01的大规模可见红外数据集。为了约束模态内和模态间的变化，[5]中提出了端到端双流超球面流形嵌入模型。在[35]中，引入了具有双向双约束顶层损失的双路径网络来学习模态对齐特征表示。Ye等人在[34]中还提出了一种分层的跨模态匹配模型，该模型联合优化了模态特定和模态共享度量。DFE[4]被提议在区域和模态上对齐信息。一些工作是基于GAN的方法，cmGAN[1]、D2RL[29]、AlignGAN[25]和JSIA ReID[26]。cmGAN采用生成对抗训练将特征映射到公共空间。D2RL应用GAN来生成缺失的模态信息，将特征提取器的输入扩展到四维。此外，AlignGAN和JSIA ReID在统一的GAN框架中实现了像素和特征双层对齐。类似地，Li等人[12]和cm SSFT[14]在这两种模态之间生成了一种新模态，以缓解模态差异。然而，这些方法建议补充模态信息或将特征直接映射到公共特征空间。

他们主要专注于缓解模态差异，而忽略了细微差别的影响，这不可避免地限制了性能的提升。



**注意机制。**人类视觉系统有一个重要的特性，即人类有选择地关注一系列一瞥中的重要部分，以捕捉有价值的信息。关于人类视觉系统，已经有几次尝试采用注意力机制来提高神经网络的性能。Hu等人引入SENet[7]来开发维度关系。他们提出了挤压和激发模块，以将注意力机制应用于具有全局平均集合特征的维度。考虑到任意两个位置之间的关系，[28]提出了非局部神经网络来捕捉它们之间的关系。为了拓宽视野，即让它同时看到“什么”和“在哪里”，CBAM[31]被提出，它利用了空间和维度方面的注意力。根据这些方法，我们提出了模态缓解模块（MAM），以通过对通道的关注来保护身份，同时缓解模态差异。我们提出了模式对齐模块（PAM）来发现不同模式中的细微差别。



**师生模型。**在半监督学习方法和知识提炼方法中，师生模型扮演着重要的角色。师生模型的关键思想是通过收集不同模型的预测，为每个样本创建一致的培训监督。时间集合[11]以指数移动的方式保存了每个样本的平均预测，作为未标记样本的监督。为了降低保存预测的成本，Mean Teacher[23]在不同的训练迭代中临时平均模型权重，以创建未标记样本的监督。与教师和学生之间的单向转移不同，深度相互学习[38]是一个学生的集合，他们在整个培训过程中协作学习并相互教授。MMT[2]将相互学习和均值教学相结合，旨在通过使用两个均值教师为另外两个网络生成软标签来减少伪标签噪声的影响。受这些方法的启发，我们制作了两个模态特定分类器来预测这两个模态的特征。以这种方式，通过使两个分类器具有模态特定知识但预测相同结果，引导网络在此过程中提取模态无关特征。
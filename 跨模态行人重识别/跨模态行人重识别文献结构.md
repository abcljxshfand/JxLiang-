# 跨模态行人重识别文献结构

## 研究背景

（可以先简单介绍传统的行人重识别系统）随着xxxxx，为了解决xxxxx问题(xxxxx应该xxxxx，但是xxxxxx)，红外模式的摄像头xxxxx，能够xxxxx。

在实际应用场景中，监控摄像头应保证全天候使用，但是可见光摄像头在夜间可能无法捕获有效的外观信息，对夜间的监控安防工作作用有限，为了克服这一缺点，红外摄像头正在普及。



## 目的与意义

红外摄像头在xxxxx模式下，分别生成xxxxx图像，为了解决两种模态图像的差异，跨模态行人重识别系统被提出，并xxxxx

## 定义

给定一个**特定个体的可见光图像**或者红**外图像**，尝试**在两种模态下的图像库中**检索匹配属于**同一个体图像**的问题。

## 方法

### 第一种流派分类（学习类型）

#### 基于表征学习的跨模态行人重识别

![image-20221114094838696](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221114094838696.png)

#### 基于度量学习的跨模态行人重识别

![image-20221114094759276](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221114094759276.png)

#### 基于模态互转的跨模态行人重识别

![image-20221114094813509](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221114094813509.png)



### 第二种流派分类

#### 基于生成对抗网络 （Generative Adversarial Networks，GANs）的跨模态图像合成方法

为了尽量减小模态差异，WANGG等人[7]利用GANs只将红外图像的风格属性迁移到它们的可见图像对应物，并将红外图像和图像特征联合输入鉴别器，以实现像素和特征的对齐

#### **基于网络参数共享的双流网络方法**

可见图像和红外图像以共享网络参数的方式实现特征对齐。

**（注：**多模态对齐是指找到两种或多种模态的instances中**sub-components之间的<font color='red'>对应关系</font>**，例如：给定一张图片和一个描述，找到词或者短语对应图片中的区域；另一个例子是给定一个电影，将它和字幕或者书中的章节对齐。）





## 困难和挑战

目前，跨模态行人重识别问题面临的**困难与挑战**主要在于：

- （1）两种**模态**下捕捉的图像存在较大**差异**。RGB图像拥有三个通道，包含了红绿蓝的可见光颜色信息，而红外图像只有一个通道，包含了近红外光的强度信息，而且从成像原理的角度出发，二者的波长范围也有所区别。不同的清晰度和光照条件在两类图像上所能产生效果可能会大相径庭。
- （2）**数据集**较为单一且规模较小。虽然现在已经有许多工作致力于扩充行人重识别数据集，然而数据集中的图像大多来源于相似型号以及角度的机位，和实际中多样化的场景差距较大。
- （3）**传统行人重识别**中存在的模态内差异，例如低分辨率、遮挡、视角变化等问题在跨模态行人重识别中也依旧存在。



## 展望

目前注意力机制因能够为不同图像信息分配不同权重，如为红外与可见光全景成像中不同大小目标分配不同权重，从而加强关键信息，过滤冗余信息，在计算机视觉领域应用广泛。在未来的研究中可以在算法中引入注意力机制，使网络学习出更鲁棒的行人特征，提高网络的识别精度。

但现有的跨模态行人重识别数据集场景较为单一且规模较小，易导致模型在现实场景中的泛化能力不高。未来可以增加更多的现实场景数据，构建更大型的跨模态行人重识别数据集以开展进一步研究，提高模型在现实场景中的泛化和落地应用能力。

本文的两项工作中用到的模型都是基于全局特征的模型，也就是说模型忽略了特征的位置信息和特征间的相互关系。即虽然模型能抽取出衣服、手袋和鞋子等特征，但是鞋子在图像中上半部分还是下半部分？手袋相对于衣服而言，在左边还是右边？这些没有在最终的特征中呈现出来。可见光-红外光跨模态行人重识别包含的两种模态的图像虽然在颜色、纹理方面差异极大，但是在人体结构等方面却没有太大差异。因此，开发利用行人图像中的位置信息和特征间的相互关系，应该可以提升跨模态行人重识别的效果。特征间的相互关系可以使用最近流行的图神经网络来进行建模，但是难点是如何从卷积网络生成的特征图中提取出适当的特征来作为图神经网络中的图结点。也就是说难点是如何去设计一个可以将卷积网络和图神经网络连接起来模块。

现有的跨模态行人重识别模型Rank-1只有60~70%，然而Rank-5却有80~90%。也就是说，正确图像的排序已经比较靠前了，但是前面还是有不少错误的图像。因此，可以考虑用二次筛选将前面的错误图像筛去。可以设计动态匹配的行人重识别算法模型来实现二次筛选。动态生成特征的例子是，如果图像C是行人背面的图像，图像A应该通过左右翻转特征，抑制脸部特征等方法去更好的比较行人图像。动态匹配要达到两个目的：细节匹配和条件匹配。细节匹配是，如果两张图像中的行人外观差不多，那么就去比较细节，比如衣服的纹理，短裤是否过膝等等。条件匹配就是，忽略一些无关的或者无法比较的特征，比如前面提到的正面图像和背面图像的比较。这是动态匹配的难点。

增强局部特征判别性。在第四章中，我们使用了局部特征提取方法代替了全局特征学习，虽然在一定程度上可以缓解无关背景因素的干扰，但当候选集中的负样本图像与查询图像在外观上很相似时（不考虑颜色特征），局部特征表示却不足以将其区分。在未来的研究工作中，我们考虑在本文的基础上，将全局特征与局部特征相融合来增强局部特征的鉴别性。同时，将尝试使用姿态估计的方法来精确定位行人的局部区域，而不是在第三章中使用简单的水平划分的方法。



## 发展

Ancong Wu-**2017**-（ICCV）RGB-Infrared Cross-Modality Person Re-Identification

![image-20221122163819418](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221122163819418.png)



**2021**-（ICCV）Channel Augmented Joint Learning for Visible-Infrared Recognition

![image-20221122164013061](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221122164013061.png)



**2022**-（ECCV）Counterfactual Intervention Feature Transfer for Visible-Infrared Person Re-identification

![image-20221122164443807](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221122164443807.png)
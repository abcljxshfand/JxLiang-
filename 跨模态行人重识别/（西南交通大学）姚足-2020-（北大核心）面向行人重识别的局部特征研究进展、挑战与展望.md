# （西南交通大学）姚足-2020-（北大核心）面向行人重识别的局部特征研究进展、挑战与展望

**（注：棕色标注表示我的一些疑问；黄色标注表示阅读文献时候的注意点，帮助我重新读的时候更快理解文章内容；绿色标注表示问题（研究目标、研究内容、关键问题），问题背景等；蓝色标注表示某项方法、行为的作用、目的、意义；红色标注表示我认为的重点，需要特别关注；紫色标注表示预备知识；）**

**（注：现阶段（基础），笔记主要围绕三点，1.知识体系结构  2.文章的诉求  3.文章的主要贡献、特点、创新点。）**

![image-20221106105213097](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20221106105213097.png)

------

## 摘要

行人重识别在实际应用中面临诸多难点,主要表现在姿势、步态、服装等行人属性多变,及光照变化、摄像视角差异、物体遮挡等环境因素干扰严重.这些差异性导致提取人体的鲁棒特征表示极为困难,其中影响行人重识别性能的最大因素是行人姿态变化及物体遮挡.

为了解决全局特征的缺陷,提取具有更能表征细节信息的局部特征成为研究的热点**.常见的局部特征有骨架、姿势、人体部件等,这些关键区域的特征可以辅助模型更加精准的区分行人特征与无关特征**.通过综合分析,本文将基于局部特征的方法归纳为4类:

1. **结合行人姿势：**

   通过额外的人体姿势或骨架预测模型**提取人体关键点**,然后将关键点特征与行人重识别模型**融合**,**生成精确的人体语义部件**(头、身、手、脚等)区域,最后针**对关键区域的特征匹配**.

2. **特征空间分割**.常用的分割方式包括网格分割和水平分割**,将特征图均匀划分得到一系列显著性区域**,使模型**对每一个区域的单独训练**,学习人体不同区域的差异.

3. **整合视角信息.**不同角度观测到的人体存在较大的姿态偏差,如俯视、侧视等角度下的行人外观有较大偏差.反过来利用视角信息,在不同角度下建模可使行人重识别方法适应更复杂的拍摄场景.

4. **融合注意力机制.**注意力机制能够指导模型**重点关注图像的特定区域**,合理融合原始特征与注意力模块可**促进模型自主学习关键区域**.



## 局部特征的行人重识别模型分类

### 基于姿势估计的方法

近年深度学习框架在姿势估计领域的成功[31−33],以及不同研究方向之间的融合,使得行人重识别领域也建立了一套基于深度学习姿势提取方法的基本架构,包含三个步骤:

1. 计算人体的关键点:使用姿势估计模型提取人体的关键点.
2. 获取行人特征:设计特征提取网络提取行人特征图.
3. 特征融合:将关键点信息与行人特征图结合,实现人体部件的划分,关键区域的对齐等.

